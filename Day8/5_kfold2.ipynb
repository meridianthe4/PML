{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829e5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967525b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D://meridianthe4//PML//Cases//Glass_Identification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "644f895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = pd.read_csv(\"Glass.csv\")\n",
    "X, y = glass.drop('Type', axis=1), glass['Type']\n",
    "# sc = StandardScaler()\n",
    "# X = sc.fit_transform(X)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "lr = LogisticRegression(max_iter=50000)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4a20807",
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'newton-cholesky', 'sag', 'saga']\n",
    "Cs = np.linspace(0.001, 15, 20)\n",
    "penalties = ['l2', None]\n",
    "params = { 'solver': solvers, 'C': Cs, 'penalty': penalties }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4985c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv = GridSearchCV(lr, param_grid=params, scoring='f1_macro', cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "994dd310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13677 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13780 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13786 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 13530 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT\n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90804e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 15. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.09884e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 11. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=5.90719e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.01947e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 14. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.37443e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.98182e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(max_iter=50000),\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e-03, 7.90421053e-01, 1.57984211e+00, 2.36926316e+00,\n",
       "       3.15868421e+00, 3.94810526e+00, 4.73752632e+00, 5.52694737e+00,\n",
       "       6.31636842e+00, 7.10578947e+00, 7.89521053e+00, 8.68463158e+00,\n",
       "       9.47405263e+00, 1.02634737e+01, 1.10528947e+01, 1.18423158e+01,\n",
       "       1.26317368e+01, 1.34211579e+01, 1.42105789e+01, 1.50000000e+01]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;newton-cholesky&#x27;,\n",
       "                                    &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">LogisticRegre...ax_iter=50000)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_grid&nbsp;</td>\n",
       "            <td class=\"value\">{&#x27;C&#x27;: array([1.0000...50000000e+01]), &#x27;penalty&#x27;: [&#x27;l2&#x27;, None], &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, ...]}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;f1_macro&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">KFold(n_split... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>LogisticRegression(C=np.float64(0.001), max_iter=50000, penalty=None,\n",
       "                   solver=&#x27;newton-cholesky&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(0.001)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;newton-cholesky&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">50000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(max_iter=50000),\n",
       "             param_grid={'C': array([1.00000000e-03, 7.90421053e-01, 1.57984211e+00, 2.36926316e+00,\n",
       "       3.15868421e+00, 3.94810526e+00, 4.73752632e+00, 5.52694737e+00,\n",
       "       6.31636842e+00, 7.10578947e+00, 7.89521053e+00, 8.68463158e+00,\n",
       "       9.47405263e+00, 1.02634737e+01, 1.10528947e+01, 1.18423158e+01,\n",
       "       1.26317368e+01, 1.34211579e+01, 1.42105789e+01, 1.50000000e+01]),\n",
       "                         'penalty': ['l2', None],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'newton-cholesky',\n",
       "                                    'sag', 'saga']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9d298e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': np.float64(0.001), 'penalty': None, 'solver': 'newton-cholesky'}\n",
      "0.5815158994962916\n"
     ]
    }
   ],
   "source": [
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b723fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = pd.DataFrame(gcv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2e87a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_fit_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "std_fit_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_score_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "std_score_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_C",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_penalty",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "param_solver",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split0_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "split1_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "split2_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "split3_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "split4_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "std_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rank_test_score",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "ad89fb5f-3446-4c3c-8264-9a82ab09e1fa",
       "rows": [
        [
         "0",
         "0.008985376358032227",
         "0.000424357841989767",
         "0.0027227401733398438",
         "0.00015968941115204676",
         "0.001",
         "l2",
         "newton-cg",
         "{'C': np.float64(0.001), 'penalty': 'l2', 'solver': 'newton-cg'}",
         "0.08187134502923976",
         "0.09836065573770492",
         "0.10855263157894736",
         "0.08187134502923976",
         "0.08333333333333333",
         "0.09079786214169303",
         "0.010839855078317355",
         "196"
        ],
        [
         "1",
         "0.029591083526611328",
         "0.002182093224490932",
         "0.002389860153198242",
         "3.285729817436345e-05",
         "0.001",
         "l2",
         "lbfgs",
         "{'C': np.float64(0.001), 'penalty': 'l2', 'solver': 'lbfgs'}",
         "0.08187134502923976",
         "0.09836065573770492",
         "0.10855263157894736",
         "0.08187134502923976",
         "0.08333333333333333",
         "0.09079786214169303",
         "0.010839855078317355",
         "196"
        ],
        [
         "2",
         "0.004750347137451172",
         "0.00013572444130825263",
         "0.0022573471069335938",
         "0.00015221998445886915",
         "0.001",
         "l2",
         "newton-cholesky",
         "{'C': np.float64(0.001), 'penalty': 'l2', 'solver': 'newton-cholesky'}",
         "0.08187134502923976",
         "0.09836065573770492",
         "0.10855263157894736",
         "0.08187134502923976",
         "0.08333333333333333",
         "0.09079786214169303",
         "0.010839855078317355",
         "196"
        ],
        [
         "3",
         "0.0029639244079589845",
         "0.00024051982951669553",
         "0.00224156379699707",
         "8.564457318053203e-05",
         "0.001",
         "l2",
         "sag",
         "{'C': np.float64(0.001), 'penalty': 'l2', 'solver': 'sag'}",
         "0.08187134502923976",
         "0.09836065573770492",
         "0.10855263157894736",
         "0.08187134502923976",
         "0.08333333333333333",
         "0.09079786214169303",
         "0.010839855078317355",
         "196"
        ],
        [
         "4",
         "0.00323944091796875",
         "3.24106886401262e-05",
         "0.00218815803527832",
         "4.981576922491051e-05",
         "0.001",
         "l2",
         "saga",
         "{'C': np.float64(0.001), 'penalty': 'l2', 'solver': 'saga'}",
         "0.08187134502923976",
         "0.09836065573770492",
         "0.10855263157894736",
         "0.08187134502923976",
         "0.08333333333333333",
         "0.09079786214169303",
         "0.010839855078317355",
         "196"
        ],
        [
         "5",
         "0.24733896255493165",
         "0.08345466771675138",
         "0.002685356140136719",
         "0.00044511244114525786",
         "0.001",
         null,
         "newton-cg",
         "{'C': np.float64(0.001), 'penalty': None, 'solver': 'newton-cg'}",
         "0.6691666666666668",
         "0.5367063492063492",
         "0.48313492063492064",
         "0.4920634920634921",
         "0.5265151515151515",
         "0.541517316017316",
         "0.06692794910476384",
         "83"
        ],
        [
         "6",
         "3.097976636886597",
         "0.527666671420291",
         "0.002479219436645508",
         "7.356232846028782e-05",
         "0.001",
         null,
         "lbfgs",
         "{'C': np.float64(0.001), 'penalty': None, 'solver': 'lbfgs'}",
         "0.6483879068868926",
         "0.6357142857142857",
         "0.481985294117647",
         "0.49898989898989904",
         "0.4854545454545454",
         "0.550106386232654",
         "0.075393910537582",
         "57"
        ],
        [
         "7",
         "0.25540661811828613",
         "0.35831417240553387",
         "0.002474069595336914",
         "7.556733187465428e-05",
         "0.001",
         null,
         "newton-cholesky",
         "{'C': np.float64(0.001), 'penalty': None, 'solver': 'newton-cholesky'}",
         "0.6869862018881626",
         "0.42559523809523814",
         "0.569760101010101",
         "0.6391865079365079",
         "0.5860514485514484",
         "0.5815158994962916",
         "0.08822687393251455",
         "1"
        ],
        [
         "8",
         "0.23448410034179687",
         "0.025963791464794675",
         "0.0024359703063964845",
         "3.870860552103147e-05",
         "0.001",
         null,
         "sag",
         "{'C': np.float64(0.001), 'penalty': None, 'solver': 'sag'}",
         "0.5566009557945041",
         "0.5190918472652218",
         "0.481985294117647",
         "0.6849462365591398",
         "0.4428904428904428",
         "0.5371029553253911",
         "0.08303753599201613",
         "104"
        ],
        [
         "9",
         "0.2770091533660889",
         "0.029349664321514472",
         "0.0024682044982910155",
         "6.503656800001668e-05",
         "0.001",
         null,
         "saga",
         "{'C': np.float64(0.001), 'penalty': None, 'solver': 'saga'}",
         "0.5835096741385957",
         "0.5",
         "0.33713624338624343",
         "0.6849462365591398",
         "0.4318316714150047",
         "0.5074847650997968",
         "0.12005864549422908",
         "142"
        ],
        [
         "10",
         "0.02931046485900879",
         "0.0047846875237522015",
         "0.002354288101196289",
         "1.498407186158602e-05",
         "0.790421052631579",
         "l2",
         "newton-cg",
         "{'C': np.float64(0.790421052631579), 'penalty': 'l2', 'solver': 'newton-cg'}",
         "0.49884259259259256",
         "0.5096525096525096",
         "0.3443963443963444",
         "0.6583333333333333",
         "0.38454631787965116",
         "0.4791542195708862",
         "0.11003024359040241",
         "190"
        ],
        [
         "11",
         "0.48494372367858884",
         "0.1029277829257481",
         "0.0023960590362548826",
         "5.2652712252302e-05",
         "0.790421052631579",
         "l2",
         "lbfgs",
         "{'C': np.float64(0.790421052631579), 'penalty': 'l2', 'solver': 'lbfgs'}",
         "0.49753882915173236",
         "0.5096525096525096",
         "0.3443963443963444",
         "0.6302921455938697",
         "0.38567119155354446",
         "0.4735102040696001",
         "0.10084671451646457",
         "194"
        ],
        [
         "12",
         "0.005607509613037109",
         "0.00027721044561158757",
         "0.002269458770751953",
         "0.00010402718174284905",
         "0.790421052631579",
         "l2",
         "newton-cholesky",
         "{'C': np.float64(0.790421052631579), 'penalty': 'l2', 'solver': 'newton-cholesky'}",
         "0.49753882915173236",
         "0.5096525096525096",
         "0.3443963443963444",
         "0.6583333333333333",
         "0.3967765567765567",
         "0.48133951466209535",
         "0.10797701704703117",
         "187"
        ],
        [
         "13",
         "0.08537397384643555",
         "0.006613661066065151",
         "0.002482175827026367",
         "0.000143132107395296",
         "0.790421052631579",
         "l2",
         "sag",
         "{'C': np.float64(0.790421052631579), 'penalty': 'l2', 'solver': 'sag'}",
         "0.5109061630800761",
         "0.5",
         "0.3541666666666667",
         "0.6469534050179212",
         "0.38454631787965116",
         "0.47931451052886304",
         "0.10408814927016953",
         "188"
        ],
        [
         "14",
         "0.14174108505249022",
         "0.012467008133060979",
         "0.0024132728576660156",
         "1.8104747734198433e-05",
         "0.790421052631579",
         "l2",
         "saga",
         "{'C': np.float64(0.790421052631579), 'penalty': 'l2', 'solver': 'saga'}",
         "0.5109061630800761",
         "0.5",
         "0.3541666666666667",
         "0.6469534050179212",
         "0.38454631787965116",
         "0.47931451052886304",
         "0.10408814927016953",
         "188"
        ],
        [
         "15",
         "0.23687825202941895",
         "0.08146301920165097",
         "0.0024829864501953124",
         "0.00022537705129786428",
         "0.790421052631579",
         null,
         "newton-cg",
         "{'C': np.float64(0.790421052631579), 'penalty': None, 'solver': 'newton-cg'}",
         "0.6691666666666668",
         "0.5367063492063492",
         "0.48313492063492064",
         "0.4920634920634921",
         "0.5265151515151515",
         "0.541517316017316",
         "0.06692794910476384",
         "83"
        ],
        [
         "16",
         "2.9694670677185058",
         "0.427894950711153",
         "0.0024114608764648437",
         "4.268973706990981e-05",
         "0.790421052631579",
         null,
         "lbfgs",
         "{'C': np.float64(0.790421052631579), 'penalty': None, 'solver': 'lbfgs'}",
         "0.6483879068868926",
         "0.6357142857142857",
         "0.481985294117647",
         "0.49898989898989904",
         "0.4854545454545454",
         "0.550106386232654",
         "0.075393910537582",
         "57"
        ],
        [
         "17",
         "0.24352092742919923",
         "0.34489025299414927",
         "0.0023645877838134764",
         "5.017142719027298e-05",
         "0.790421052631579",
         null,
         "newton-cholesky",
         "{'C': np.float64(0.790421052631579), 'penalty': None, 'solver': 'newton-cholesky'}",
         "0.6869862018881626",
         "0.42559523809523814",
         "0.569760101010101",
         "0.6391865079365079",
         "0.5860514485514484",
         "0.5815158994962916",
         "0.08822687393251455",
         "1"
        ],
        [
         "18",
         "0.2348360538482666",
         "0.02610069854753182",
         "0.0024193286895751952",
         "3.962244214944186e-05",
         "0.790421052631579",
         null,
         "sag",
         "{'C': np.float64(0.790421052631579), 'penalty': None, 'solver': 'sag'}",
         "0.5566009557945041",
         "0.5190918472652218",
         "0.481985294117647",
         "0.6849462365591398",
         "0.4428904428904428",
         "0.5371029553253911",
         "0.08303753599201613",
         "104"
        ],
        [
         "19",
         "0.27977943420410156",
         "0.03152630646683869",
         "0.0024231910705566407",
         "4.131033800505826e-05",
         "0.790421052631579",
         null,
         "saga",
         "{'C': np.float64(0.790421052631579), 'penalty': None, 'solver': 'saga'}",
         "0.5835096741385957",
         "0.5",
         "0.33713624338624343",
         "0.6849462365591398",
         "0.4318316714150047",
         "0.5074847650997968",
         "0.12005864549422908",
         "142"
        ],
        [
         "20",
         "0.036800575256347653",
         "0.003991403890278293",
         "0.002373075485229492",
         "8.678182137090267e-05",
         "1.579842105263158",
         "l2",
         "newton-cg",
         "{'C': np.float64(1.579842105263158), 'penalty': 'l2', 'solver': 'newton-cg'}",
         "0.5709064327485379",
         "0.5190918472652218",
         "0.33713624338624343",
         "0.6374883286647992",
         "0.38567119155354446",
         "0.4900588087236694",
         "0.11260266834789452",
         "183"
        ],
        [
         "21",
         "0.5332126140594482",
         "0.0702184397845234",
         "0.0024094581604003906",
         "0.00010893115015958952",
         "1.579842105263158",
         "l2",
         "lbfgs",
         "{'C': np.float64(1.579842105263158), 'penalty': 'l2', 'solver': 'lbfgs'}",
         "0.5697378503730591",
         "0.5190918472652218",
         "0.33713624338624343",
         "0.6374883286647992",
         "0.38567119155354446",
         "0.48982509224857357",
         "0.11243570860369465",
         "185"
        ],
        [
         "22",
         "0.006445169448852539",
         "0.00030205189471252717",
         "0.00227813720703125",
         "8.763268095259637e-05",
         "1.579842105263158",
         "l2",
         "newton-cholesky",
         "{'C': np.float64(1.579842105263158), 'penalty': 'l2', 'solver': 'newton-cholesky'}",
         "0.5709064327485379",
         "0.5190918472652218",
         "0.33713624338624343",
         "0.6374883286647992",
         "0.38567119155354446",
         "0.4900588087236694",
         "0.11260266834789452",
         "183"
        ],
        [
         "23",
         "0.11631569862365723",
         "0.011066581299782116",
         "0.0024756431579589845",
         "6.953057558942799e-05",
         "1.579842105263158",
         "l2",
         "sag",
         "{'C': np.float64(1.579842105263158), 'penalty': 'l2', 'solver': 'sag'}",
         "0.4964478545041205",
         "0.5",
         "0.33713624338624343",
         "0.6469534050179212",
         "0.38454631787965116",
         "0.4730167641575873",
         "0.10753753003936833",
         "195"
        ],
        [
         "24",
         "0.19325413703918456",
         "0.02827209466739343",
         "0.0024866580963134764",
         "6.410621170871885e-05",
         "1.579842105263158",
         "l2",
         "saga",
         "{'C': np.float64(1.579842105263158), 'penalty': 'l2', 'solver': 'saga'}",
         "0.5109061630800761",
         "0.5",
         "0.33713624338624343",
         "0.6469534050179212",
         "0.38454631787965116",
         "0.4759084258727784",
         "0.10832025097214724",
         "191"
        ],
        [
         "25",
         "0.23852763175964356",
         "0.08073357357900389",
         "0.0023766517639160155",
         "1.3408030065074656e-05",
         "1.579842105263158",
         null,
         "newton-cg",
         "{'C': np.float64(1.579842105263158), 'penalty': None, 'solver': 'newton-cg'}",
         "0.6691666666666668",
         "0.5367063492063492",
         "0.48313492063492064",
         "0.4920634920634921",
         "0.5265151515151515",
         "0.541517316017316",
         "0.06692794910476384",
         "83"
        ],
        [
         "26",
         "2.968796634674072",
         "0.4351649741092194",
         "0.0025595664978027345",
         "0.0002596650709186309",
         "1.579842105263158",
         null,
         "lbfgs",
         "{'C': np.float64(1.579842105263158), 'penalty': None, 'solver': 'lbfgs'}",
         "0.6483879068868926",
         "0.6357142857142857",
         "0.481985294117647",
         "0.49898989898989904",
         "0.4854545454545454",
         "0.550106386232654",
         "0.075393910537582",
         "57"
        ],
        [
         "27",
         "0.25101513862609864",
         "0.3671929152442682",
         "0.002402496337890625",
         "5.11102707621396e-05",
         "1.579842105263158",
         null,
         "newton-cholesky",
         "{'C': np.float64(1.579842105263158), 'penalty': None, 'solver': 'newton-cholesky'}",
         "0.6869862018881626",
         "0.42559523809523814",
         "0.569760101010101",
         "0.6391865079365079",
         "0.5860514485514484",
         "0.5815158994962916",
         "0.08822687393251455",
         "1"
        ],
        [
         "28",
         "0.23508777618408203",
         "0.02557931079893512",
         "0.002409696578979492",
         "3.329470854739434e-05",
         "1.579842105263158",
         null,
         "sag",
         "{'C': np.float64(1.579842105263158), 'penalty': None, 'solver': 'sag'}",
         "0.5566009557945041",
         "0.5190918472652218",
         "0.481985294117647",
         "0.6849462365591398",
         "0.4428904428904428",
         "0.5371029553253911",
         "0.08303753599201613",
         "104"
        ],
        [
         "29",
         "0.27808775901794436",
         "0.029651719824931838",
         "0.002517414093017578",
         "0.00010946070903008296",
         "1.579842105263158",
         null,
         "saga",
         "{'C': np.float64(1.579842105263158), 'penalty': None, 'solver': 'saga'}",
         "0.5835096741385957",
         "0.5",
         "0.33713624338624343",
         "0.6849462365591398",
         "0.4318316714150047",
         "0.5074847650997968",
         "0.12005864549422908",
         "142"
        ],
        [
         "30",
         "0.042003631591796875",
         "0.006396589658728728",
         "0.002447366714477539",
         "0.00010273721879201237",
         "2.369263157894737",
         "l2",
         "newton-cg",
         "{'C': np.float64(2.369263157894737), 'penalty': 'l2', 'solver': 'newton-cg'}",
         "0.5566009557945041",
         "0.5190918472652218",
         "0.43894830659536543",
         "0.6854978354978355",
         "0.38567119155354446",
         "0.5171620273412942",
         "0.10325049501021791",
         "136"
        ],
        [
         "31",
         "0.6413997650146485",
         "0.0720449432055725",
         "0.0023983478546142577",
         "6.479102860677282e-05",
         "2.369263157894737",
         "l2",
         "lbfgs",
         "{'C': np.float64(2.369263157894737), 'penalty': 'l2', 'solver': 'lbfgs'}",
         "0.5551851851851851",
         "0.5190918472652218",
         "0.43894830659536543",
         "0.6854978354978355",
         "0.38567119155354446",
         "0.5168788732194305",
         "0.10314383565960263",
         "138"
        ],
        [
         "32",
         "0.007343769073486328",
         "0.0008901987201058039",
         "0.002239370346069336",
         "7.798403123331097e-05",
         "2.369263157894737",
         "l2",
         "newton-cholesky",
         "{'C': np.float64(2.369263157894737), 'penalty': 'l2', 'solver': 'newton-cholesky'}",
         "0.5566009557945041",
         "0.5190918472652218",
         "0.43894830659536543",
         "0.6854978354978355",
         "0.38567119155354446",
         "0.5171620273412942",
         "0.10325049501021791",
         "136"
        ],
        [
         "33",
         "0.13484930992126465",
         "0.013487804266410755",
         "0.002472591400146484",
         "0.00012608528461806863",
         "2.369263157894737",
         "l2",
         "sag",
         "{'C': np.float64(2.369263157894737), 'penalty': 'l2', 'solver': 'sag'}",
         "0.569092190016103",
         "0.5",
         "0.33713624338624343",
         "0.6469534050179212",
         "0.38454631787965116",
         "0.48754563125998385",
         "0.11440946936116127",
         "186"
        ],
        [
         "34",
         "0.20806441307067872",
         "0.01777519729208338",
         "0.0023965358734130858",
         "3.574860609556271e-05",
         "2.369263157894737",
         "l2",
         "saga",
         "{'C': np.float64(2.369263157894737), 'penalty': 'l2', 'solver': 'saga'}",
         "0.5109061630800761",
         "0.5",
         "0.33713624338624343",
         "0.6469534050179212",
         "0.38454631787965116",
         "0.4759084258727784",
         "0.10832025097214724",
         "191"
        ],
        [
         "35",
         "0.2371211528778076",
         "0.0819032000406681",
         "0.002414560317993164",
         "5.5120313005239966e-05",
         "2.369263157894737",
         null,
         "newton-cg",
         "{'C': np.float64(2.369263157894737), 'penalty': None, 'solver': 'newton-cg'}",
         "0.6691666666666668",
         "0.5367063492063492",
         "0.48313492063492064",
         "0.4920634920634921",
         "0.5265151515151515",
         "0.541517316017316",
         "0.06692794910476384",
         "83"
        ],
        [
         "36",
         "2.9527120113372805",
         "0.44441445454543343",
         "0.0024576187133789062",
         "8.52796295791346e-05",
         "2.369263157894737",
         null,
         "lbfgs",
         "{'C': np.float64(2.369263157894737), 'penalty': None, 'solver': 'lbfgs'}",
         "0.6483879068868926",
         "0.6357142857142857",
         "0.481985294117647",
         "0.49898989898989904",
         "0.4854545454545454",
         "0.550106386232654",
         "0.075393910537582",
         "57"
        ],
        [
         "37",
         "0.2704709529876709",
         "0.4059860627031483",
         "0.0023791313171386717",
         "3.9827293776681506e-05",
         "2.369263157894737",
         null,
         "newton-cholesky",
         "{'C': np.float64(2.369263157894737), 'penalty': None, 'solver': 'newton-cholesky'}",
         "0.6869862018881626",
         "0.42559523809523814",
         "0.569760101010101",
         "0.6391865079365079",
         "0.5860514485514484",
         "0.5815158994962916",
         "0.08822687393251455",
         "1"
        ],
        [
         "38",
         "0.2347411632537842",
         "0.02581867196651808",
         "0.002459001541137695",
         "9.489100182987365e-05",
         "2.369263157894737",
         null,
         "sag",
         "{'C': np.float64(2.369263157894737), 'penalty': None, 'solver': 'sag'}",
         "0.5566009557945041",
         "0.5190918472652218",
         "0.481985294117647",
         "0.6849462365591398",
         "0.4428904428904428",
         "0.5371029553253911",
         "0.08303753599201613",
         "104"
        ],
        [
         "39",
         "0.27725019454956057",
         "0.030361456560438028",
         "0.0024370193481445313",
         "5.2349814496354365e-05",
         "2.369263157894737",
         null,
         "saga",
         "{'C': np.float64(2.369263157894737), 'penalty': None, 'solver': 'saga'}",
         "0.5835096741385957",
         "0.5",
         "0.33713624338624343",
         "0.6849462365591398",
         "0.4318316714150047",
         "0.5074847650997968",
         "0.12005864549422908",
         "142"
        ],
        [
         "40",
         "0.044957733154296874",
         "0.00581117602564361",
         "0.0024021625518798827",
         "3.6753165489433414e-05",
         "3.158684210526316",
         "l2",
         "newton-cg",
         "{'C': np.float64(3.158684210526316), 'penalty': 'l2', 'solver': 'newton-cg'}",
         "0.5566009557945041",
         "0.5190918472652218",
         "0.42914438502673796",
         "0.6780022446689112",
         "0.4994560994560994",
         "0.5364591064422949",
         "0.08200908208754536",
         "124"
        ],
        [
         "41",
         "0.78159499168396",
         "0.08924808652185584",
         "0.002424001693725586",
         "8.468337956180872e-05",
         "3.158684210526316",
         "l2",
         "lbfgs",
         "{'C': np.float64(3.158684210526316), 'penalty': 'l2', 'solver': 'lbfgs'}",
         "0.5429069653207584",
         "0.5281853281853283",
         "0.42914438502673796",
         "0.6780022446689112",
         "0.4875515334338863",
         "0.5331580913271244",
         "0.08246018056725264",
         "127"
        ],
        [
         "42",
         "0.007012271881103515",
         "0.0008589155052609466",
         "0.0022325038909912108",
         "9.190959225046334e-05",
         "3.158684210526316",
         "l2",
         "newton-cholesky",
         "{'C': np.float64(3.158684210526316), 'penalty': 'l2', 'solver': 'newton-cholesky'}",
         "0.5566009557945041",
         "0.5190918472652218",
         "0.42914438502673796",
         "0.6780022446689112",
         "0.4994560994560994",
         "0.5364591064422949",
         "0.08200908208754536",
         "124"
        ],
        [
         "43",
         "0.14749269485473632",
         "0.015047204886329617",
         "0.002424001693725586",
         "3.1411591245683585e-05",
         "3.158684210526316",
         "l2",
         "sag",
         "{'C': np.float64(3.158684210526316), 'penalty': 'l2', 'solver': 'sag'}",
         "0.569092190016103",
         "0.5",
         "0.33713624338624343",
         "0.6849462365591398",
         "0.4318316714150047",
         "0.5046012682752983",
         "0.11835920499084222",
         "174"
        ],
        [
         "44",
         "0.22271575927734374",
         "0.02256562134995335",
         "0.0025156021118164064",
         "0.0001461621710838147",
         "3.158684210526316",
         "l2",
         "saga",
         "{'C': np.float64(3.158684210526316), 'penalty': 'l2', 'solver': 'saga'}",
         "0.5109061630800761",
         "0.5",
         "0.33713624338624343",
         "0.6469534050179212",
         "0.38454631787965116",
         "0.4759084258727784",
         "0.10832025097214724",
         "191"
        ],
        [
         "45",
         "0.23746485710144044",
         "0.08111822416180263",
         "0.002389955520629883",
         "5.368991597573259e-05",
         "3.158684210526316",
         null,
         "newton-cg",
         "{'C': np.float64(3.158684210526316), 'penalty': None, 'solver': 'newton-cg'}",
         "0.6691666666666668",
         "0.5367063492063492",
         "0.48313492063492064",
         "0.4920634920634921",
         "0.5265151515151515",
         "0.541517316017316",
         "0.06692794910476384",
         "83"
        ],
        [
         "46",
         "2.9080636501312256",
         "0.39867994412672647",
         "0.002505207061767578",
         "5.785109773061358e-05",
         "3.158684210526316",
         null,
         "lbfgs",
         "{'C': np.float64(3.158684210526316), 'penalty': None, 'solver': 'lbfgs'}",
         "0.6483879068868926",
         "0.6357142857142857",
         "0.481985294117647",
         "0.49898989898989904",
         "0.4854545454545454",
         "0.550106386232654",
         "0.075393910537582",
         "57"
        ],
        [
         "47",
         "0.25291857719421384",
         "0.37403828801761824",
         "0.002378082275390625",
         "5.731427925294e-05",
         "3.158684210526316",
         null,
         "newton-cholesky",
         "{'C': np.float64(3.158684210526316), 'penalty': None, 'solver': 'newton-cholesky'}",
         "0.6869862018881626",
         "0.42559523809523814",
         "0.569760101010101",
         "0.6391865079365079",
         "0.5860514485514484",
         "0.5815158994962916",
         "0.08822687393251455",
         "1"
        ],
        [
         "48",
         "0.2349160671234131",
         "0.026708999721471994",
         "0.0024444103240966798",
         "2.7505941359828736e-05",
         "3.158684210526316",
         null,
         "sag",
         "{'C': np.float64(3.158684210526316), 'penalty': None, 'solver': 'sag'}",
         "0.5566009557945041",
         "0.5190918472652218",
         "0.481985294117647",
         "0.6849462365591398",
         "0.4428904428904428",
         "0.5371029553253911",
         "0.08303753599201613",
         "104"
        ],
        [
         "49",
         "0.2763340950012207",
         "0.02898668224341378",
         "0.0024619102478027344",
         "7.003535108355274e-05",
         "3.158684210526316",
         null,
         "saga",
         "{'C': np.float64(3.158684210526316), 'penalty': None, 'solver': 'saga'}",
         "0.5835096741385957",
         "0.5",
         "0.33713624338624343",
         "0.6849462365591398",
         "0.4318316714150047",
         "0.5074847650997968",
         "0.12005864549422908",
         "142"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 200
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'newto...</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.108553</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.090798</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029591</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.108553</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.090798</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'newto...</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.108553</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.090798</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'sag'}</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.108553</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.090798</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.108553</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.090798</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.236136</td>\n",
       "      <td>0.078995</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>15.000</td>\n",
       "      <td>None</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 15.0, 'penalty': None, 'solver': 'newton...</td>\n",
       "      <td>0.669167</td>\n",
       "      <td>0.536706</td>\n",
       "      <td>0.483135</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.526515</td>\n",
       "      <td>0.541517</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2.909745</td>\n",
       "      <td>0.397760</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>15.000</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 15.0, 'penalty': None, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.648388</td>\n",
       "      <td>0.635714</td>\n",
       "      <td>0.481985</td>\n",
       "      <td>0.498990</td>\n",
       "      <td>0.485455</td>\n",
       "      <td>0.550106</td>\n",
       "      <td>0.075394</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.255171</td>\n",
       "      <td>0.359799</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>15.000</td>\n",
       "      <td>None</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>{'C': 15.0, 'penalty': None, 'solver': 'newton...</td>\n",
       "      <td>0.686986</td>\n",
       "      <td>0.425595</td>\n",
       "      <td>0.569760</td>\n",
       "      <td>0.639187</td>\n",
       "      <td>0.586051</td>\n",
       "      <td>0.581516</td>\n",
       "      <td>0.088227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.236287</td>\n",
       "      <td>0.025803</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>15.000</td>\n",
       "      <td>None</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 15.0, 'penalty': None, 'solver': 'sag'}</td>\n",
       "      <td>0.556601</td>\n",
       "      <td>0.519092</td>\n",
       "      <td>0.481985</td>\n",
       "      <td>0.684946</td>\n",
       "      <td>0.442890</td>\n",
       "      <td>0.537103</td>\n",
       "      <td>0.083038</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.279814</td>\n",
       "      <td>0.029177</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>15.000</td>\n",
       "      <td>None</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 15.0, 'penalty': None, 'solver': 'saga'}</td>\n",
       "      <td>0.583510</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.337136</td>\n",
       "      <td>0.684946</td>\n",
       "      <td>0.431832</td>\n",
       "      <td>0.507485</td>\n",
       "      <td>0.120059</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_C  \\\n",
       "0         0.008985      0.000424         0.002723        0.000160    0.001   \n",
       "1         0.029591      0.002182         0.002390        0.000033    0.001   \n",
       "2         0.004750      0.000136         0.002257        0.000152    0.001   \n",
       "3         0.002964      0.000241         0.002242        0.000086    0.001   \n",
       "4         0.003239      0.000032         0.002188        0.000050    0.001   \n",
       "..             ...           ...              ...             ...      ...   \n",
       "195       0.236136      0.078995         0.002399        0.000036   15.000   \n",
       "196       2.909745      0.397760         0.002486        0.000110   15.000   \n",
       "197       0.255171      0.359799         0.002380        0.000028   15.000   \n",
       "198       0.236287      0.025803         0.002435        0.000060   15.000   \n",
       "199       0.279814      0.029177         0.002471        0.000069   15.000   \n",
       "\n",
       "    param_penalty     param_solver  \\\n",
       "0              l2        newton-cg   \n",
       "1              l2            lbfgs   \n",
       "2              l2  newton-cholesky   \n",
       "3              l2              sag   \n",
       "4              l2             saga   \n",
       "..            ...              ...   \n",
       "195          None        newton-cg   \n",
       "196          None            lbfgs   \n",
       "197          None  newton-cholesky   \n",
       "198          None              sag   \n",
       "199          None             saga   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'C': 0.001, 'penalty': 'l2', 'solver': 'newto...           0.081871   \n",
       "1     {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}           0.081871   \n",
       "2    {'C': 0.001, 'penalty': 'l2', 'solver': 'newto...           0.081871   \n",
       "3       {'C': 0.001, 'penalty': 'l2', 'solver': 'sag'}           0.081871   \n",
       "4      {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}           0.081871   \n",
       "..                                                 ...                ...   \n",
       "195  {'C': 15.0, 'penalty': None, 'solver': 'newton...           0.669167   \n",
       "196    {'C': 15.0, 'penalty': None, 'solver': 'lbfgs'}           0.648388   \n",
       "197  {'C': 15.0, 'penalty': None, 'solver': 'newton...           0.686986   \n",
       "198      {'C': 15.0, 'penalty': None, 'solver': 'sag'}           0.556601   \n",
       "199     {'C': 15.0, 'penalty': None, 'solver': 'saga'}           0.583510   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0             0.098361           0.108553           0.081871   \n",
       "1             0.098361           0.108553           0.081871   \n",
       "2             0.098361           0.108553           0.081871   \n",
       "3             0.098361           0.108553           0.081871   \n",
       "4             0.098361           0.108553           0.081871   \n",
       "..                 ...                ...                ...   \n",
       "195           0.536706           0.483135           0.492063   \n",
       "196           0.635714           0.481985           0.498990   \n",
       "197           0.425595           0.569760           0.639187   \n",
       "198           0.519092           0.481985           0.684946   \n",
       "199           0.500000           0.337136           0.684946   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0             0.083333         0.090798        0.010840              196  \n",
       "1             0.083333         0.090798        0.010840              196  \n",
       "2             0.083333         0.090798        0.010840              196  \n",
       "3             0.083333         0.090798        0.010840              196  \n",
       "4             0.083333         0.090798        0.010840              196  \n",
       "..                 ...              ...             ...              ...  \n",
       "195           0.526515         0.541517        0.066928               83  \n",
       "196           0.485455         0.550106        0.075394               57  \n",
       "197           0.586051         0.581516        0.088227                1  \n",
       "198           0.442890         0.537103        0.083038              104  \n",
       "199           0.431832         0.507485        0.120059              142  \n",
       "\n",
       "[200 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "602f4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [None, 3, 4, 5, 6, 7]\n",
    "min_samples = [2, 10, 0.025, 0.01, 0.05, 0.1]\n",
    "min_leaf = [1, 10, 0.025, 0.01, 0.05, 0.1]\n",
    "params = { 'max_depth': depths, 'min_samples_split': min_samples, 'min_samples_leaf': min_leaf }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deb9fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "gcv = GridSearchCV(dtc, param_grid=params, scoring='f1_macro', cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1517d283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 3, 4, 5, 6, 7],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 10, 0.025, 0.01, 0.05, 0.1],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 10, 0.025, 0.01, 0.05, 0.1]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">DecisionTreeClassifier()</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_grid&nbsp;</td>\n",
       "            <td class=\"value\">{&#x27;max_depth&#x27;: [None, 3, ...], &#x27;min_samples_leaf&#x27;: [1, 10, ...], &#x27;min_samples_split&#x27;: [2, 10, ...]}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;f1_macro&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">KFold(n_split... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: DecisionTreeClassifier</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>DecisionTreeClassifier(max_depth=6, min_samples_leaf=0.01,\n",
       "                       min_samples_split=0.025)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">splitter&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;best&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">0.025</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.01</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [None, 3, 4, 5, 6, 7],\n",
       "                         'min_samples_leaf': [1, 10, 0.025, 0.01, 0.05, 0.1],\n",
       "                         'min_samples_split': [2, 10, 0.025, 0.01, 0.05, 0.1]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5642b74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'min_samples_leaf': 0.01, 'min_samples_split': 0.025}\n",
      "0.7300681937260707\n"
     ]
    }
   ],
   "source": [
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50ec9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = pd.DataFrame(gcv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c9c1e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_fit_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "std_fit_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_score_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "std_score_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_max_depth",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "param_min_samples_leaf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_min_samples_split",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "params",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split0_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "split1_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "split2_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "split3_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "split4_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "std_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rank_test_score",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "dba9d1bf-aa3b-4754-80e1-6ffa2d414b75",
       "rows": [
        [
         "0",
         "0.002481842041015625",
         "0.0003947207650312639",
         "0.0036457061767578127",
         "0.0016834105854106852",
         null,
         "1.0",
         "2.0",
         "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}",
         "0.7785127153548205",
         "0.5777019140989729",
         "0.7513227513227513",
         "0.6752270717787958",
         "0.5840373972557881",
         "0.6733603699622257",
         "0.08278619070339746",
         "19"
        ],
        [
         "1",
         "0.0023482322692871095",
         "0.0004778502288416784",
         "0.0024021148681640627",
         "0.000175089799694549",
         null,
         "1.0",
         "10.0",
         "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10}",
         "0.796891996891997",
         "0.6231822955960887",
         "0.6368233618233617",
         "0.6813131313131313",
         "0.6330912382636521",
         "0.6742604047776461",
         "0.06448822222742048",
         "18"
        ],
        [
         "2",
         "0.002010631561279297",
         "6.094053503782532e-05",
         "0.0023078441619873045",
         "9.806563948340261e-05",
         null,
         "1.0",
         "0.025",
         "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 0.025}",
         "0.6789987789987789",
         "0.578042328042328",
         "0.717989417989418",
         "0.8233477011494252",
         "0.6010989010989011",
         "0.6798954254557702",
         "0.08787884540336847",
         "14"
        ],
        [
         "3",
         "0.002038717269897461",
         "0.00011970141871662883",
         "0.002190971374511719",
         "3.960378760921088e-05",
         null,
         "1.0",
         "0.01",
         "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 0.01}",
         "0.7785127153548205",
         "0.5873203687605311",
         "0.7062678062678063",
         "0.661344537815126",
         "0.5971021103205012",
         "0.666109507703757",
         "0.07104874985652107",
         "26"
        ],
        [
         "4",
         "0.0019205093383789062",
         "4.7189150477285084e-05",
         "0.0021359920501708984",
         "1.5231943356718275e-05",
         null,
         "1.0",
         "0.05",
         "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 0.05}",
         "0.66256038647343",
         "0.6203703703703703",
         "0.6872201872201872",
         "0.8029793906810037",
         "0.620026525198939",
         "0.6786313719887861",
         "0.06726566204540994",
         "16"
        ],
        [
         "5",
         "0.0018425464630126953",
         "5.782943757926078e-05",
         "0.002161073684692383",
         "3.793940098816003e-05",
         null,
         "1.0",
         "0.1",
         "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 0.1}",
         "0.7441310541310542",
         "0.4065656565656565",
         "0.6084144051885987",
         "0.7786855482933914",
         "0.6214285714285716",
         "0.6318450471214544",
         "0.13082704759416022",
         "63"
        ],
        [
         "6",
         "0.0018057823181152344",
         "0.00012263042870921083",
         "0.0022930622100830076",
         "0.00017842653907955853",
         null,
         "10.0",
         "2.0",
         "{'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 2}",
         "0.6338624338624338",
         "0.46068875893437294",
         "0.4713804713804714",
         "0.7978653530377668",
         "0.5492753623188406",
         "0.5826144759067772",
         "0.12434602849894928",
         "125"
        ],
        [
         "7",
         "0.0017159938812255859",
         "8.019822652060815e-05",
         "0.002254152297973633",
         "0.0001994198100716124",
         null,
         "10.0",
         "10.0",
         "{'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 10}",
         "0.6338624338624338",
         "0.46068875893437294",
         "0.4713804713804714",
         "0.7978653530377668",
         "0.5492753623188406",
         "0.5826144759067772",
         "0.12434602849894928",
         "125"
        ],
        [
         "8",
         "0.001791524887084961",
         "0.00011624253268254405",
         "0.0022727012634277343",
         "0.00017067710506349858",
         null,
         "10.0",
         "0.025",
         "{'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 0.025}",
         "0.6338624338624338",
         "0.46068875893437294",
         "0.4713804713804714",
         "0.7978653530377668",
         "0.5492753623188406",
         "0.5826144759067772",
         "0.12434602849894928",
         "125"
        ],
        [
         "9",
         "0.0018398761749267578",
         "0.00014295256714776382",
         "0.0022597312927246094",
         "8.380336747561418e-05",
         null,
         "10.0",
         "0.01",
         "{'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 0.01}",
         "0.6338624338624338",
         "0.46068875893437294",
         "0.4713804713804714",
         "0.7978653530377668",
         "0.5492753623188406",
         "0.5826144759067772",
         "0.12434602849894928",
         "125"
        ],
        [
         "10",
         "0.0017346382141113282",
         "0.00010338876467128871",
         "0.002172231674194336",
         "5.436633718753919e-05",
         null,
         "10.0",
         "0.05",
         "{'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 0.05}",
         "0.6338624338624338",
         "0.46068875893437294",
         "0.4713804713804714",
         "0.7978653530377668",
         "0.5492753623188406",
         "0.5826144759067772",
         "0.12434602849894928",
         "125"
        ],
        [
         "11",
         "0.0017215251922607423",
         "9.996121945810504e-05",
         "0.002284860610961914",
         "9.018963608528914e-05",
         null,
         "10.0",
         "0.1",
         "{'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 0.1}",
         "0.6338624338624338",
         "0.46068875893437294",
         "0.4713804713804714",
         "0.7978653530377668",
         "0.5492753623188406",
         "0.5826144759067772",
         "0.12434602849894928",
         "125"
        ],
        [
         "12",
         "0.0017958641052246093",
         "6.601958119926944e-05",
         "0.0021948814392089844",
         "8.967936663116814e-05",
         null,
         "0.025",
         "2.0",
         "{'max_depth': None, 'min_samples_leaf': 0.025, 'min_samples_split': 2}",
         "0.6338624338624338",
         "0.6763736263736263",
         "0.7185449735449735",
         "0.7545177045177045",
         "0.5143298059964726",
         "0.6595257088590422",
         "0.0831036209313287",
         "32"
        ],
        [
         "13",
         "0.0018140792846679688",
         "5.460532940999875e-05",
         "0.00222163200378418",
         "8.672256155607787e-05",
         null,
         "0.025",
         "10.0",
         "{'max_depth': None, 'min_samples_leaf': 0.025, 'min_samples_split': 10}",
         "0.573015873015873",
         "0.6763736263736263",
         "0.7185449735449735",
         "0.7545177045177045",
         "0.5143298059964726",
         "0.64735639668973",
         "0.0901287371266008",
         "50"
        ],
        [
         "14",
         "0.0017891407012939453",
         "1.9337143124396965e-05",
         "0.0021392345428466798",
         "3.22556988222805e-05",
         null,
         "0.025",
         "0.025",
         "{'max_depth': None, 'min_samples_leaf': 0.025, 'min_samples_split': 0.025}",
         "0.6468071519795657",
         "0.6861111111111112",
         "0.7185449735449735",
         "0.7545177045177045",
         "0.5365520282186949",
         "0.66850659387441",
         "0.07495937939607289",
         "25"
        ],
        [
         "15",
         "0.0017727851867675782",
         "3.928067468843043e-05",
         "0.002145862579345703",
         "5.404893974119777e-05",
         null,
         "0.025",
         "0.01",
         "{'max_depth': None, 'min_samples_leaf': 0.025, 'min_samples_split': 0.01}",
         "0.573015873015873",
         "0.6861111111111112",
         "0.7185449735449735",
         "0.7801587301587302",
         "0.5143298059964726",
         "0.6544320987654321",
         "0.0971374908381141",
         "39"
        ],
        [
         "16",
         "0.001810455322265625",
         "4.855167090680965e-05",
         "0.002193260192871094",
         "9.89746022544942e-05",
         null,
         "0.025",
         "0.05",
         "{'max_depth': None, 'min_samples_leaf': 0.025, 'min_samples_split': 0.05}",
         "0.6338624338624338",
         "0.6763736263736263",
         "0.7185449735449735",
         "0.7801587301587302",
         "0.5365520282186949",
         "0.6690983584316916",
         "0.08202731675621136",
         "24"
        ],
        [
         "17",
         "0.0017845630645751953",
         "8.268485568751283e-05",
         "0.002149200439453125",
         "4.3424552328997964e-05",
         null,
         "0.025",
         "0.1",
         "{'max_depth': None, 'min_samples_leaf': 0.025, 'min_samples_split': 0.1}",
         "0.6468071519795657",
         "0.46527777777777773",
         "0.6388888888888888",
         "0.818482905982906",
         "0.553615520282187",
         "0.624614448982265",
         "0.11722651320232061",
         "82"
        ],
        [
         "18",
         "0.0018865108489990235",
         "5.691278710401634e-05",
         "0.002129268646240234",
         "1.9102313192341827e-05",
         null,
         "0.01",
         "2.0",
         "{'max_depth': None, 'min_samples_leaf': 0.01, 'min_samples_split': 2}",
         "0.5420173961840627",
         "0.6075268817204301",
         "0.7292872704637411",
         "0.6520833333333335",
         "0.5926929392446634",
         "0.6247215641892462",
         "0.0629986073907226",
         "81"
        ],
        [
         "19",
         "0.001897287368774414",
         "5.606019353833722e-05",
         "0.0022498130798339843",
         "0.00012585056079219553",
         null,
         "0.01",
         "10.0",
         "{'max_depth': None, 'min_samples_leaf': 0.01, 'min_samples_split': 10}",
         "0.6137949543746646",
         "0.6231822955960887",
         "0.667877145438121",
         "0.8525774991292233",
         "0.6330912382636521",
         "0.67810462656035",
         "0.08913336763936087",
         "17"
        ],
        [
         "20",
         "0.0019655704498291017",
         "0.00010135929518751155",
         "0.0022731781005859374",
         "0.00017245147921543286",
         null,
         "0.01",
         "0.025",
         "{'max_depth': None, 'min_samples_leaf': 0.01, 'min_samples_split': 0.025}",
         "0.7864468864468867",
         "0.6951447245564891",
         "0.7387187187187187",
         "0.6520833333333335",
         "0.5801587301587302",
         "0.6905104786428317",
         "0.07099782937369879",
         "8"
        ],
        [
         "21",
         "0.0019601821899414063",
         "0.00014211032156493205",
         "0.0022066593170166015",
         "0.0001553260428786847",
         null,
         "0.01",
         "0.01",
         "{'max_depth': None, 'min_samples_leaf': 0.01, 'min_samples_split': 0.01}",
         "0.7059432941785883",
         "0.6428571428571428",
         "0.5565599977364682",
         "0.6813131313131313",
         "0.5850151640474222",
         "0.6343377460265505",
         "0.056371476286322046",
         "62"
        ],
        [
         "22",
         "0.0018549919128417968",
         "6.717764064886187e-05",
         "0.002182483673095703",
         "7.730426006913686e-05",
         null,
         "0.01",
         "0.05",
         "{'max_depth': None, 'min_samples_leaf': 0.01, 'min_samples_split': 0.05}",
         "0.6296544035674471",
         "0.6149721149721149",
         "0.7185449735449735",
         "0.7687500000000002",
         "0.6330912382636521",
         "0.6730025460696376",
         "0.06013516860711674",
         "20"
        ],
        [
         "23",
         "0.001805877685546875",
         "5.988334348803444e-05",
         "0.002140188217163086",
         "2.8572295790361456e-05",
         null,
         "0.01",
         "0.1",
         "{'max_depth': None, 'min_samples_leaf': 0.01, 'min_samples_split': 0.1}",
         "0.7084045584045584",
         "0.4065656565656565",
         "0.6388888888888888",
         "0.7786855482933914",
         "0.6214285714285716",
         "0.6307946447162134",
         "0.12516141362909375",
         "69"
        ],
        [
         "24",
         "0.0016753196716308594",
         "5.0956336763999185e-05",
         "0.002144479751586914",
         "3.3844556537217275e-05",
         null,
         "0.05",
         "2.0",
         "{'max_depth': None, 'min_samples_leaf': 0.05, 'min_samples_split': 2}",
         "0.6338624338624338",
         "0.47211497211497205",
         "0.638047138047138",
         "0.7679012345679013",
         "0.553615520282187",
         "0.6131082597749264",
         "0.09841955258413126",
         "97"
        ],
        [
         "25",
         "0.0016866207122802734",
         "6.436513923204415e-05",
         "0.0021519184112548826",
         "4.161545588715187e-05",
         null,
         "0.05",
         "10.0",
         "{'max_depth': None, 'min_samples_leaf': 0.05, 'min_samples_split': 10}",
         "0.6338624338624338",
         "0.47211497211497205",
         "0.638047138047138",
         "0.7679012345679013",
         "0.553615520282187",
         "0.6131082597749264",
         "0.09841955258413126",
         "97"
        ],
        [
         "26",
         "0.0016982078552246094",
         "8.420563491561344e-05",
         "0.002197742462158203",
         "7.540045519368588e-05",
         null,
         "0.05",
         "0.025",
         "{'max_depth': None, 'min_samples_leaf': 0.05, 'min_samples_split': 0.025}",
         "0.6338624338624338",
         "0.47211497211497205",
         "0.638047138047138",
         "0.7836299592139415",
         "0.553615520282187",
         "0.6162540047041345",
         "0.10344017404549932",
         "91"
        ],
        [
         "27",
         "0.0017193317413330077",
         "4.7092250407986944e-05",
         "0.0021656513214111327",
         "3.57896703765546e-05",
         null,
         "0.05",
         "0.01",
         "{'max_depth': None, 'min_samples_leaf': 0.05, 'min_samples_split': 0.01}",
         "0.6338624338624338",
         "0.46068875893437294",
         "0.638047138047138",
         "0.713600159299084",
         "0.553615520282187",
         "0.5999628020850432",
         "0.086091091596002",
         "108"
        ],
        [
         "28",
         "0.0016756057739257812",
         "4.9445277279062285e-05",
         "0.002159309387207031",
         "3.725175665045351e-05",
         null,
         "0.05",
         "0.05",
         "{'max_depth': None, 'min_samples_leaf': 0.05, 'min_samples_split': 0.05}",
         "0.6338624338624338",
         "0.47211497211497205",
         "0.638047138047138",
         "0.7679012345679013",
         "0.553615520282187",
         "0.6131082597749264",
         "0.09841955258413126",
         "97"
        ],
        [
         "29",
         "0.0016907215118408202",
         "6.716731663337024e-05",
         "0.002133941650390625",
         "2.3203211655609476e-05",
         null,
         "0.05",
         "0.1",
         "{'max_depth': None, 'min_samples_leaf': 0.05, 'min_samples_split': 0.1}",
         "0.6338624338624338",
         "0.46068875893437294",
         "0.638047138047138",
         "0.7836299592139415",
         "0.553615520282187",
         "0.6139687620680145",
         "0.10667494676722641",
         "94"
        ],
        [
         "30",
         "0.0015672206878662109",
         "6.887773691967543e-05",
         "0.0021297454833984373",
         "1.8948143140473716e-05",
         null,
         "0.1",
         "2.0",
         "{'max_depth': None, 'min_samples_leaf': 0.1, 'min_samples_split': 2}",
         "0.40063032999629217",
         "0.46428571428571425",
         "0.47222222222222215",
         "0.48939974457215846",
         "0.4497835497835498",
         "0.4552643121719874",
         "0.030163205795302173",
         "187"
        ],
        [
         "31",
         "0.0016312122344970704",
         "8.579351361861676e-05",
         "0.002228260040283203",
         "0.000131488051721269",
         null,
         "0.1",
         "10.0",
         "{'max_depth': None, 'min_samples_leaf': 0.1, 'min_samples_split': 10}",
         "0.40063032999629217",
         "0.46428571428571425",
         "0.47222222222222215",
         "0.48939974457215846",
         "0.4497835497835498",
         "0.4552643121719874",
         "0.030163205795302173",
         "187"
        ],
        [
         "32",
         "0.00159454345703125",
         "7.049775739580775e-05",
         "0.0021726131439208985",
         "6.749572285412702e-05",
         null,
         "0.1",
         "0.025",
         "{'max_depth': None, 'min_samples_leaf': 0.1, 'min_samples_split': 0.025}",
         "0.40063032999629217",
         "0.46428571428571425",
         "0.47222222222222215",
         "0.48939974457215846",
         "0.4371972113907598",
         "0.4527470444934294",
         "0.03102835190822004",
         "200"
        ],
        [
         "33",
         "0.0015454769134521484",
         "4.997958614008233e-05",
         "0.0021429538726806642",
         "5.959079581543431e-05",
         null,
         "0.1",
         "0.01",
         "{'max_depth': None, 'min_samples_leaf': 0.1, 'min_samples_split': 0.01}",
         "0.40063032999629217",
         "0.46428571428571425",
         "0.47222222222222215",
         "0.48939974457215846",
         "0.4371972113907598",
         "0.4527470444934294",
         "0.03102835190822004",
         "200"
        ],
        [
         "34",
         "0.001558685302734375",
         "5.225504363746517e-05",
         "0.0021997928619384766",
         "0.00010571842204598138",
         null,
         "0.1",
         "0.05",
         "{'max_depth': None, 'min_samples_leaf': 0.1, 'min_samples_split': 0.05}",
         "0.40063032999629217",
         "0.46428571428571425",
         "0.47222222222222215",
         "0.48939974457215846",
         "0.4497835497835498",
         "0.4552643121719874",
         "0.030163205795302173",
         "187"
        ],
        [
         "35",
         "0.001636505126953125",
         "4.926537893035266e-05",
         "0.002393007278442383",
         "0.00028090577764011427",
         null,
         "0.1",
         "0.1",
         "{'max_depth': None, 'min_samples_leaf': 0.1, 'min_samples_split': 0.1}",
         "0.40063032999629217",
         "0.46428571428571425",
         "0.47222222222222215",
         "0.48939974457215846",
         "0.4371972113907598",
         "0.4527470444934294",
         "0.03102835190822004",
         "200"
        ],
        [
         "36",
         "0.0017455577850341796",
         "0.00017097259460145456",
         "0.0023709774017333985",
         "0.00024486888546381374",
         "3",
         "1.0",
         "2.0",
         "{'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}",
         "0.5573192239858906",
         "0.40811965811965806",
         "0.47222222222222215",
         "0.6244778613199666",
         "0.47807539682539685",
         "0.5080428724946269",
         "0.075034768999441",
         "171"
        ],
        [
         "37",
         "0.0015252113342285156",
         "2.530087357034039e-05",
         "0.0021662235260009764",
         "7.850011279891226e-05",
         "3",
         "1.0",
         "10.0",
         "{'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 10}",
         "0.5573192239858906",
         "0.40811965811965806",
         "0.47222222222222215",
         "0.6244778613199666",
         "0.47807539682539685",
         "0.5080428724946269",
         "0.075034768999441",
         "171"
        ],
        [
         "38",
         "0.0015288829803466798",
         "3.519646148365405e-05",
         "0.0021301746368408204",
         "4.9093760698140965e-05",
         "3",
         "1.0",
         "0.025",
         "{'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 0.025}",
         "0.5573192239858906",
         "0.46637426900584794",
         "0.47222222222222215",
         "0.6244778613199666",
         "0.4650106837606837",
         "0.5170808520589222",
         "0.06394998176059345",
         "169"
        ],
        [
         "39",
         "0.0015310287475585938",
         "6.92484454329903e-05",
         "0.0021234989166259766",
         "3.3125805652233795e-05",
         "3",
         "1.0",
         "0.01",
         "{'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 0.01}",
         "0.5573192239858906",
         "0.40811965811965806",
         "0.47222222222222215",
         "0.6215913715913716",
         "0.4650106837606837",
         "0.5048526319359652",
         "0.07535259692074449",
         "180"
        ],
        [
         "40",
         "0.0015642642974853516",
         "8.178584387853493e-05",
         "0.0021389484405517577",
         "5.16055018001897e-05",
         "3",
         "1.0",
         "0.05",
         "{'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 0.05}",
         "0.5573192239858906",
         "0.40811965811965806",
         "0.47222222222222215",
         "0.6244778613199666",
         "0.4650106837606837",
         "0.5054299298816842",
         "0.07625046244810915",
         "177"
        ],
        [
         "41",
         "0.0016404151916503905",
         "0.00012410364718810205",
         "0.00228118896484375",
         "0.0002227714105573095",
         "3",
         "1.0",
         "0.1",
         "{'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 0.1}",
         "0.5573192239858906",
         "0.46637426900584794",
         "0.47222222222222215",
         "0.6244778613199666",
         "0.4650106837606837",
         "0.5170808520589222",
         "0.06394998176059345",
         "169"
        ],
        [
         "42",
         "0.001499176025390625",
         "3.3266355612687046e-05",
         "0.002140665054321289",
         "9.551854082949556e-05",
         "3",
         "10.0",
         "2.0",
         "{'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 2}",
         "0.5573192239858906",
         "0.4396825396825397",
         "0.47222222222222215",
         "0.6531746031746032",
         "0.4676587301587302",
         "0.5180114638447971",
         "0.0782069652131388",
         "163"
        ],
        [
         "43",
         "0.0014840126037597655",
         "5.041470084469473e-05",
         "0.00213475227355957",
         "4.386160622047201e-05",
         "3",
         "10.0",
         "10.0",
         "{'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 10}",
         "0.5573192239858906",
         "0.4396825396825397",
         "0.47222222222222215",
         "0.6531746031746032",
         "0.4676587301587302",
         "0.5180114638447971",
         "0.0782069652131388",
         "163"
        ],
        [
         "44",
         "0.0015941143035888671",
         "0.00010251238151535579",
         "0.0022368431091308594",
         "5.844183596479e-05",
         "3",
         "10.0",
         "0.025",
         "{'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 0.025}",
         "0.5573192239858906",
         "0.4396825396825397",
         "0.47222222222222215",
         "0.6531746031746032",
         "0.4676587301587302",
         "0.5180114638447971",
         "0.0782069652131388",
         "163"
        ],
        [
         "45",
         "0.0015637397766113282",
         "7.697862130170174e-05",
         "0.0021394729614257813",
         "4.9256978398726644e-05",
         "3",
         "10.0",
         "0.01",
         "{'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 0.01}",
         "0.5573192239858906",
         "0.4396825396825397",
         "0.47222222222222215",
         "0.6531746031746032",
         "0.4676587301587302",
         "0.5180114638447971",
         "0.0782069652131388",
         "163"
        ],
        [
         "46",
         "0.001558685302734375",
         "8.907269614534848e-05",
         "0.0021764755249023436",
         "8.985052074343737e-05",
         "3",
         "10.0",
         "0.05",
         "{'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 0.05}",
         "0.5573192239858906",
         "0.4396825396825397",
         "0.47222222222222215",
         "0.6531746031746032",
         "0.4676587301587302",
         "0.5180114638447971",
         "0.0782069652131388",
         "163"
        ],
        [
         "47",
         "0.001557779312133789",
         "5.507384543160796e-05",
         "0.0021418094635009765",
         "8.014448249724666e-05",
         "3",
         "10.0",
         "0.1",
         "{'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 0.1}",
         "0.5573192239858906",
         "0.4396825396825397",
         "0.47222222222222215",
         "0.6531746031746032",
         "0.4676587301587302",
         "0.5180114638447971",
         "0.0782069652131388",
         "163"
        ],
        [
         "48",
         "0.0015307426452636718",
         "6.329994866152215e-05",
         "0.0021849155426025392",
         "8.573346459539708e-05",
         "3",
         "0.025",
         "2.0",
         "{'max_depth': 3, 'min_samples_leaf': 0.025, 'min_samples_split': 2}",
         "0.5573192239858906",
         "0.46637426900584794",
         "0.47222222222222215",
         "0.6531746031746032",
         "0.47807539682539685",
         "0.5254331430427921",
         "0.07196764775702028",
         "151"
        ],
        [
         "49",
         "0.001563262939453125",
         "6.407587915739436e-05",
         "0.002186012268066406",
         "4.8122390886169066e-05",
         "3",
         "0.025",
         "10.0",
         "{'max_depth': 3, 'min_samples_leaf': 0.025, 'min_samples_split': 10}",
         "0.5573192239858906",
         "0.46637426900584794",
         "0.47222222222222215",
         "0.6531746031746032",
         "0.47807539682539685",
         "0.5254331430427921",
         "0.07196764775702028",
         "151"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 216
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'mi...</td>\n",
       "      <td>0.778513</td>\n",
       "      <td>0.577702</td>\n",
       "      <td>0.751323</td>\n",
       "      <td>0.675227</td>\n",
       "      <td>0.584037</td>\n",
       "      <td>0.673360</td>\n",
       "      <td>0.082786</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'mi...</td>\n",
       "      <td>0.796892</td>\n",
       "      <td>0.623182</td>\n",
       "      <td>0.636823</td>\n",
       "      <td>0.681313</td>\n",
       "      <td>0.633091</td>\n",
       "      <td>0.674260</td>\n",
       "      <td>0.064488</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'mi...</td>\n",
       "      <td>0.678999</td>\n",
       "      <td>0.578042</td>\n",
       "      <td>0.717989</td>\n",
       "      <td>0.823348</td>\n",
       "      <td>0.601099</td>\n",
       "      <td>0.679895</td>\n",
       "      <td>0.087879</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'mi...</td>\n",
       "      <td>0.778513</td>\n",
       "      <td>0.587320</td>\n",
       "      <td>0.706268</td>\n",
       "      <td>0.661345</td>\n",
       "      <td>0.597102</td>\n",
       "      <td>0.666110</td>\n",
       "      <td>0.071049</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'mi...</td>\n",
       "      <td>0.662560</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>0.687220</td>\n",
       "      <td>0.802979</td>\n",
       "      <td>0.620027</td>\n",
       "      <td>0.678631</td>\n",
       "      <td>0.067266</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.000</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 0.1, 'min...</td>\n",
       "      <td>0.400630</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.489400</td>\n",
       "      <td>0.449784</td>\n",
       "      <td>0.455264</td>\n",
       "      <td>0.030163</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.025</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 0.1, 'min...</td>\n",
       "      <td>0.400630</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.489400</td>\n",
       "      <td>0.449784</td>\n",
       "      <td>0.455264</td>\n",
       "      <td>0.030163</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 0.1, 'min...</td>\n",
       "      <td>0.400630</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.489400</td>\n",
       "      <td>0.449784</td>\n",
       "      <td>0.455264</td>\n",
       "      <td>0.030163</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.050</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 0.1, 'min...</td>\n",
       "      <td>0.400630</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.489400</td>\n",
       "      <td>0.437197</td>\n",
       "      <td>0.452747</td>\n",
       "      <td>0.031028</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 0.1, 'min...</td>\n",
       "      <td>0.400630</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.489400</td>\n",
       "      <td>0.437197</td>\n",
       "      <td>0.452747</td>\n",
       "      <td>0.031028</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.002482      0.000395         0.003646        0.001683   \n",
       "1         0.002348      0.000478         0.002402        0.000175   \n",
       "2         0.002011      0.000061         0.002308        0.000098   \n",
       "3         0.002039      0.000120         0.002191        0.000040   \n",
       "4         0.001921      0.000047         0.002136        0.000015   \n",
       "..             ...           ...              ...             ...   \n",
       "211       0.001912      0.000156         0.002666        0.000322   \n",
       "212       0.001943      0.000253         0.002531        0.000189   \n",
       "213       0.001811      0.000131         0.002399        0.000245   \n",
       "214       0.001863      0.000149         0.002596        0.000269   \n",
       "215       0.001755      0.000115         0.002337        0.000068   \n",
       "\n",
       "    param_max_depth  param_min_samples_leaf  param_min_samples_split  \\\n",
       "0              None                     1.0                    2.000   \n",
       "1              None                     1.0                   10.000   \n",
       "2              None                     1.0                    0.025   \n",
       "3              None                     1.0                    0.010   \n",
       "4              None                     1.0                    0.050   \n",
       "..              ...                     ...                      ...   \n",
       "211               7                     0.1                   10.000   \n",
       "212               7                     0.1                    0.025   \n",
       "213               7                     0.1                    0.010   \n",
       "214               7                     0.1                    0.050   \n",
       "215               7                     0.1                    0.100   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'max_depth': None, 'min_samples_leaf': 1, 'mi...           0.778513   \n",
       "1    {'max_depth': None, 'min_samples_leaf': 1, 'mi...           0.796892   \n",
       "2    {'max_depth': None, 'min_samples_leaf': 1, 'mi...           0.678999   \n",
       "3    {'max_depth': None, 'min_samples_leaf': 1, 'mi...           0.778513   \n",
       "4    {'max_depth': None, 'min_samples_leaf': 1, 'mi...           0.662560   \n",
       "..                                                 ...                ...   \n",
       "211  {'max_depth': 7, 'min_samples_leaf': 0.1, 'min...           0.400630   \n",
       "212  {'max_depth': 7, 'min_samples_leaf': 0.1, 'min...           0.400630   \n",
       "213  {'max_depth': 7, 'min_samples_leaf': 0.1, 'min...           0.400630   \n",
       "214  {'max_depth': 7, 'min_samples_leaf': 0.1, 'min...           0.400630   \n",
       "215  {'max_depth': 7, 'min_samples_leaf': 0.1, 'min...           0.400630   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0             0.577702           0.751323           0.675227   \n",
       "1             0.623182           0.636823           0.681313   \n",
       "2             0.578042           0.717989           0.823348   \n",
       "3             0.587320           0.706268           0.661345   \n",
       "4             0.620370           0.687220           0.802979   \n",
       "..                 ...                ...                ...   \n",
       "211           0.464286           0.472222           0.489400   \n",
       "212           0.464286           0.472222           0.489400   \n",
       "213           0.464286           0.472222           0.489400   \n",
       "214           0.464286           0.472222           0.489400   \n",
       "215           0.464286           0.472222           0.489400   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0             0.584037         0.673360        0.082786               19  \n",
       "1             0.633091         0.674260        0.064488               18  \n",
       "2             0.601099         0.679895        0.087879               14  \n",
       "3             0.597102         0.666110        0.071049               26  \n",
       "4             0.620027         0.678631        0.067266               16  \n",
       "..                 ...              ...             ...              ...  \n",
       "211           0.449784         0.455264        0.030163              187  \n",
       "212           0.449784         0.455264        0.030163              187  \n",
       "213           0.449784         0.455264        0.030163              187  \n",
       "214           0.437197         0.452747        0.031028              200  \n",
       "215           0.437197         0.452747        0.031028              200  \n",
       "\n",
       "[216 rows x 16 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35994923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
