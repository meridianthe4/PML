{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b26113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90035ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'X': [0.2, 1.2, 1.0, 1.4, -1.5, 0.5, -0.5],\n",
    "    'Y': [5.6, 8.6, 8.0, 9.2, 0.5, 6.5, 3.5]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465372c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['X']\n",
    "y = df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42201bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.3\n",
    "b = 0.1\n",
    "eta = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc467bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = b+ w*x \n",
    "# L = np.mean((y-y_pred) **2)/2 \n",
    "# dw = -np.mean((y-y_pred)*x) \n",
    "# db = -np.mean(y-y_pred) \n",
    "# print(f\"Loss = {L}, dw= {dw}, db = {db}\") \n",
    "# new_w, new_b = w - eta*dw, b - eta*db \n",
    "# print(f\"Updated parameters: w = {new_w}, b = {new_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c53c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = 0\n",
    "L = 0\n",
    "dw = 0\n",
    "db = 0\n",
    "new_w = 0\n",
    "new_b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64515a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 22.050714285714285, dw= -4.724285714285713, db = -5.985714285714286\n",
      "Updated parameters: w = 0.9448571428571427, b = 1.1971428571428573\n",
      "Loss = 11.9679097277551, dw= -3.360435510204081, db = -4.478118367346939\n",
      "Updated parameters: w = 1.616944244897959, b = 2.092766530612245\n",
      "Loss = 6.5295265283340616, dw= -2.3758296941107866, db = -3.3616660746355684\n",
      "Updated parameters: w = 2.0921101837201164, b = 2.7650997455393584\n",
      "Loss = 3.587393588594775, dw= -1.6668569091874055, db = -2.533206908381174\n",
      "Updated parameters: w = 2.4254815655575976, b = 3.271741127215593\n",
      "Loss = 1.9891986420605754, dw= -1.1579689930064296, db = -1.9170292155297675\n",
      "Updated parameters: w = 2.6570753641588833, b = 3.655146970321547\n",
      "Loss = 1.1162410865968448, dw= -0.7941128714225814, db = -1.4575282671691057\n",
      "Updated parameters: w = 2.8158979384433995, b = 3.946652623755368\n",
      "Loss = 0.6358948125005485, dw= -0.5351989697078011, db = -1.113838053613229\n",
      "Updated parameters: w = 2.92293773238496, b = 4.169420234478014\n",
      "Loss = 0.3690119263816961, dw= -0.3520587378361003, db = -0.8559002248812134\n",
      "Updated parameters: w = 2.99334947995218, b = 4.340600279454256\n",
      "Loss = 0.21886761175563324, dw= -0.22349094234271924, db = -0.6615848914185987\n",
      "Updated parameters: w = 3.038047668420724, b = 4.4729172577379765\n",
      "Loss = 0.13306230752331963, dw= -0.1341039387510927, db = -0.514581365495214\n",
      "Updated parameters: w = 3.0648684561709425, b = 4.575833530837019\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    y_pred = new_b + new_w*x\n",
    "    L = np.mean((y - y_pred) ** 2) / 2\n",
    "    dw = -np.mean((y - y_pred) * x)\n",
    "    db = -np.mean(y - y_pred)\n",
    "    print(f\"Loss = {L}, dw= {dw}, db = {db}\")\n",
    "    new_w, new_b = new_w - eta * dw, new_b - eta * db\n",
    "    print(f\"Updated parameters: w = {new_w}, b = {new_b}\")\n",
    "    w, b = new_w, new_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c574b97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th iteration:\n",
      "Loss = 20.095936, dw = -4.383286, db = -5.787143\n",
      "w=0.300000, b=0.100000\n",
      "\n",
      "2th iteration:\n",
      "Loss = 0.950943, dw = 1.208010, db = 1.042621\n",
      "w=3.941526, b=5.733262\n",
      "\n",
      "3th iteration:\n",
      "Loss = 0.509947, dw = 0.891335, db = 0.754713\n",
      "w=3.699924, b=5.524738\n",
      "\n",
      "4th iteration:\n",
      "Loss = 0.273686, dw = 0.658634, db = 0.545197\n",
      "w=3.521656, b=5.373795\n",
      "\n",
      "5th iteration:\n",
      "Loss = 0.147054, dw = 0.487505, db = 0.392876\n",
      "w=3.389930, b=5.264756\n",
      "\n",
      "6th iteration:\n",
      "Loss = 0.079138, dw = 0.361540, db = 0.282265\n",
      "w=3.292429, b=5.186181\n",
      "\n",
      "7th iteration:\n",
      "Loss = 0.042681, dw = 0.268720, db = 0.202053\n",
      "w=3.220121, b=5.129728\n",
      "\n",
      "8th iteration:\n",
      "Loss = 0.023088, dw = 0.200240, db = 0.143984\n",
      "w=3.166377, b=5.089317\n",
      "\n",
      "9th iteration:\n",
      "Loss = 0.012540, dw = 0.149643, db = 0.102029\n",
      "w=3.126329, b=5.060521\n",
      "\n",
      "10th iteration:\n",
      "Loss = 0.006848, dw = 0.112197, db = 0.071789\n",
      "w=3.096400, b=5.040115\n",
      "\n",
      "11th iteration:\n",
      "Loss = 0.003767, dw = 0.084431, db = 0.050058\n",
      "w=3.073961, b=5.025757\n",
      "\n",
      "12th iteration:\n",
      "Loss = 0.002092, dw = 0.063797, db = 0.034498\n",
      "w=3.057074, b=5.015745\n",
      "\n",
      "13th iteration:\n",
      "Loss = 0.001176, dw = 0.048424, db = 0.023406\n",
      "w=3.044315, b=5.008846\n",
      "\n",
      "14th iteration:\n",
      "Loss = 0.000672, dw = 0.036938, db = 0.015543\n",
      "w=3.034630, b=5.004164\n",
      "\n",
      "15th iteration:\n",
      "Loss = 0.000391, dw = 0.028329, db = 0.010007\n",
      "w=3.027242, b=5.001056\n",
      "\n",
      "16th iteration:\n",
      "Loss = 0.000233, dw = 0.021852, db = 0.006144\n",
      "w=3.021577, b=4.999054\n",
      "\n",
      "17th iteration:\n",
      "Loss = 0.000142, dw = 0.016959, db = 0.003479\n",
      "w=3.017206, b=4.997826\n",
      "\n",
      "18th iteration:\n",
      "Loss = 0.000089, dw = 0.013246, db = 0.001669\n",
      "w=3.013815, b=4.997130\n",
      "\n",
      "\n",
      "Final parameters:\n",
      "w = 3.0138145828051197\n",
      "b = 4.997129812004519\n"
     ]
    }
   ],
   "source": [
    "eta = 0.2\n",
    "w, b = 0.3, 0.1\n",
    "for i in range(100):\n",
    "    y_pred = b + w * x\n",
    "\n",
    "    L = np.mean((y - y_pred) ** 2) / 2\n",
    "\n",
    "    dw = -np.mean((y - y_pred) * x)\n",
    "    db = -np.mean(y - y_pred)\n",
    "\n",
    "    print(f\"{i+1}th iteration:\")\n",
    "    print(f\"Loss = {L:.6f}, dw = {dw:.6f}, db = {db:.6f}\")\n",
    "    print(f\"w={w:.6f}, b={b:.6f}\\n\")\n",
    "    if L < 0.0001:\n",
    "        break\n",
    "    new_w, new_b = new_w - eta * dw, new_b - eta * db\n",
    "    w, b = new_w, new_b\n",
    "\n",
    "print(\"\\nFinal parameters:\")\n",
    "print(\"w =\", w)\n",
    "print(\"b =\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501a646",
   "metadata": {},
   "source": [
    "## 2 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5fd6685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th iteration:\n",
      "Loss = 51.648482, dw1 = -3.758833, dw2 = -4.915927, db = -5.774000\n",
      "w1=0.300000, w2=0.100000, b=-0.300000\n",
      "\n",
      "2th iteration:\n",
      "Loss = 38.434118, dw1 = -3.332392, dw2 = -4.391041, db = -4.571780\n",
      "w1=1.051767, w2=1.083185, b=0.854800\n",
      "\n",
      "3th iteration:\n",
      "Loss = 28.943456, dw1 = -2.958216, dw2 = -3.924583, db = -3.615318\n",
      "w1=1.718245, w2=1.961394, b=1.769156\n",
      "\n",
      "4th iteration:\n",
      "Loss = 22.033811, dw1 = -2.629201, dw2 = -3.509593, db = -2.854823\n",
      "w1=2.309888, w2=2.746310, b=2.492220\n",
      "\n",
      "5th iteration:\n",
      "Loss = 16.936249, dw1 = -2.339326, dw2 = -3.140023, db = -2.250547\n",
      "w1=2.835728, w2=3.448229, b=3.063184\n",
      "\n",
      "6th iteration:\n",
      "Loss = 13.128088, dw1 = -2.083466, dw2 = -2.810606, db = -1.770764\n",
      "w1=3.303594, w2=4.076233, b=3.513294\n",
      "\n",
      "7th iteration:\n",
      "Loss = 10.250022, dw1 = -1.857249, dw2 = -2.516739, db = -1.390156\n",
      "w1=3.720287, w2=4.638355, b=3.867446\n",
      "\n",
      "8th iteration:\n",
      "Loss = 8.052007, dw1 = -1.656932, dw2 = -2.254394, db = -1.088519\n",
      "w1=4.091736, w2=5.141702, b=4.145478\n",
      "\n",
      "9th iteration:\n",
      "Loss = 6.357748, dw1 = -1.479298, dw2 = -2.020033, db = -0.849737\n",
      "w1=4.423123, w2=5.592581, b=4.363181\n",
      "\n",
      "10th iteration:\n",
      "Loss = 5.041256, dw1 = -1.321575, dw2 = -1.810547, db = -0.660956\n",
      "w1=4.718983, w2=5.996588, b=4.533129\n",
      "\n",
      "11th iteration:\n",
      "Loss = 4.011256, dw1 = -1.181365, dw2 = -1.623196, db = -0.511928\n",
      "w1=4.983298, w2=6.358697, b=4.665320\n",
      "\n",
      "12th iteration:\n",
      "Loss = 3.200727, dw1 = -1.056591, dw2 = -1.455559, db = -0.394483\n",
      "w1=5.219571, w2=6.683336, b=4.767706\n",
      "\n",
      "13th iteration:\n",
      "Loss = 2.559826, dw1 = -0.945446, dw2 = -1.305498, db = -0.302109\n",
      "w1=5.430889, w2=6.974448, b=4.846602\n",
      "\n",
      "14th iteration:\n",
      "Loss = 2.051036, dw1 = -0.846354, dw2 = -1.171118, db = -0.229622\n",
      "w1=5.619978, w2=7.235548, b=4.907024\n",
      "\n",
      "15th iteration:\n",
      "Loss = 1.645808, dw1 = -0.757937, dw2 = -1.050738, db = -0.172892\n",
      "w1=5.789249, w2=7.469771, b=4.952948\n",
      "\n",
      "16th iteration:\n",
      "Loss = 1.322209, dw1 = -0.678990, dw2 = -0.942868, db = -0.128632\n",
      "w1=5.940836, w2=7.679919, b=4.987527\n",
      "\n",
      "17th iteration:\n",
      "Loss = 1.063242, dw1 = -0.608452, dw2 = -0.846179, db = -0.094230\n",
      "w1=6.076634, w2=7.868493, b=5.013253\n",
      "\n",
      "18th iteration:\n",
      "Loss = 0.855643, dw1 = -0.545392, dw2 = -0.759492, db = -0.067607\n",
      "w1=6.198325, w2=8.037728, b=5.032099\n",
      "\n",
      "19th iteration:\n",
      "Loss = 0.688992, dw1 = -0.488987, dw2 = -0.681755, db = -0.047113\n",
      "w1=6.307403, w2=8.189627, b=5.045621\n",
      "\n",
      "20th iteration:\n",
      "Loss = 0.555064, dw1 = -0.438511, dw2 = -0.612029, db = -0.031437\n",
      "w1=6.405200, w2=8.325978, b=5.055043\n",
      "\n",
      "21th iteration:\n",
      "Loss = 0.447339, dw1 = -0.393322, dw2 = -0.549479, db = -0.019540\n",
      "w1=6.492902, w2=8.448384, b=5.061331\n",
      "\n",
      "22th iteration:\n",
      "Loss = 0.360630, dw1 = -0.352852, dw2 = -0.493357, db = -0.010600\n",
      "w1=6.571567, w2=8.558279, b=5.065239\n",
      "\n",
      "23th iteration:\n",
      "Loss = 0.290797, dw1 = -0.316595, dw2 = -0.442995, db = -0.003965\n",
      "w1=6.642137, w2=8.656951, b=5.067359\n",
      "\n",
      "24th iteration:\n",
      "Loss = 0.234532, dw1 = -0.284103, dw2 = -0.397797, db = 0.000880\n",
      "w1=6.705456, w2=8.745550, b=5.068152\n",
      "\n",
      "25th iteration:\n",
      "Loss = 0.189181, dw1 = -0.254977, dw2 = -0.357228, db = 0.004341\n",
      "w1=6.762277, w2=8.825109, b=5.067976\n",
      "\n",
      "26th iteration:\n",
      "Loss = 0.152618, dw1 = -0.228862, dw2 = -0.320812, db = 0.006737\n",
      "w1=6.813272, w2=8.896555, b=5.067108\n",
      "\n",
      "27th iteration:\n",
      "Loss = 0.123133, dw1 = -0.205443, dw2 = -0.288119, db = 0.008320\n",
      "w1=6.859045, w2=8.960717, b=5.065760\n",
      "\n",
      "28th iteration:\n",
      "Loss = 0.099352, dw1 = -0.184435, dw2 = -0.258767, db = 0.009286\n",
      "w1=6.900133, w2=9.018341, b=5.064096\n",
      "\n",
      "29th iteration:\n",
      "Loss = 0.080168, dw1 = -0.165589, dw2 = -0.232412, db = 0.009791\n",
      "w1=6.937021, w2=9.070094, b=5.062239\n",
      "\n",
      "30th iteration:\n",
      "Loss = 0.064692, dw1 = -0.148679, dw2 = -0.208748, db = 0.009954\n",
      "w1=6.970138, w2=9.116577, b=5.060281\n",
      "\n",
      "31th iteration:\n",
      "Loss = 0.052205, dw1 = -0.133504, dw2 = -0.187498, db = 0.009867\n",
      "w1=6.999874, w2=9.158327, b=5.058290\n",
      "\n",
      "32th iteration:\n",
      "Loss = 0.042130, dw1 = -0.119885, dw2 = -0.168415, db = 0.009604\n",
      "w1=7.026575, w2=9.195826, b=5.056317\n",
      "\n",
      "33th iteration:\n",
      "Loss = 0.034000, dw1 = -0.107660, dw2 = -0.151277, db = 0.009219\n",
      "w1=7.050552, w2=9.229509, b=5.054396\n",
      "\n",
      "34th iteration:\n",
      "Loss = 0.027439, dw1 = -0.096686, dw2 = -0.135885, db = 0.008754\n",
      "w1=7.072084, w2=9.259764, b=5.052552\n",
      "\n",
      "35th iteration:\n",
      "Loss = 0.022145, dw1 = -0.086834, dw2 = -0.122062, db = 0.008242\n",
      "w1=7.091421, w2=9.286941, b=5.050801\n",
      "\n",
      "36th iteration:\n",
      "Loss = 0.017872, dw1 = -0.077988, dw2 = -0.109646, db = 0.007706\n",
      "w1=7.108788, w2=9.311354, b=5.049153\n",
      "\n",
      "37th iteration:\n",
      "Loss = 0.014424, dw1 = -0.070046, dw2 = -0.098494, db = 0.007164\n",
      "w1=7.124385, w2=9.333283, b=5.047612\n",
      "\n",
      "38th iteration:\n",
      "Loss = 0.011641, dw1 = -0.062914, dw2 = -0.088478, db = 0.006629\n",
      "w1=7.138395, w2=9.352982, b=5.046179\n",
      "\n",
      "39th iteration:\n",
      "Loss = 0.009395, dw1 = -0.056510, dw2 = -0.079481, db = 0.006109\n",
      "w1=7.150978, w2=9.370677, b=5.044853\n",
      "\n",
      "40th iteration:\n",
      "Loss = 0.007583, dw1 = -0.050759, dw2 = -0.071399, db = 0.005611\n",
      "w1=7.162280, w2=9.386573, b=5.043632\n",
      "\n",
      "41th iteration:\n",
      "Loss = 0.006120, dw1 = -0.045594, dw2 = -0.064140, db = 0.005139\n",
      "w1=7.172431, w2=9.400853, b=5.042509\n",
      "\n",
      "42th iteration:\n",
      "Loss = 0.004939, dw1 = -0.040955, dw2 = -0.057619, db = 0.004696\n",
      "w1=7.181550, w2=9.413681, b=5.041481\n",
      "\n",
      "43th iteration:\n",
      "Loss = 0.003986, dw1 = -0.036789, dw2 = -0.051761, db = 0.004281\n",
      "w1=7.189741, w2=9.425205, b=5.040542\n",
      "\n",
      "44th iteration:\n",
      "Loss = 0.003217, dw1 = -0.033047, dw2 = -0.046500, db = 0.003897\n",
      "w1=7.197099, w2=9.435557, b=5.039686\n",
      "\n",
      "45th iteration:\n",
      "Loss = 0.002597, dw1 = -0.029686, dw2 = -0.041773, db = 0.003541\n",
      "w1=7.203708, w2=9.444857, b=5.038907\n",
      "\n",
      "46th iteration:\n",
      "Loss = 0.002096, dw1 = -0.026667, dw2 = -0.037527, db = 0.003213\n",
      "w1=7.209646, w2=9.453212, b=5.038199\n",
      "\n",
      "47th iteration:\n",
      "Loss = 0.001692, dw1 = -0.023955, dw2 = -0.033712, db = 0.002912\n",
      "w1=7.214979, w2=9.460717, b=5.037556\n",
      "\n",
      "48th iteration:\n",
      "Loss = 0.001365, dw1 = -0.021520, dw2 = -0.030286, db = 0.002637\n",
      "w1=7.219770, w2=9.467460, b=5.036974\n",
      "\n",
      "49th iteration:\n",
      "Loss = 0.001102, dw1 = -0.019332, dw2 = -0.027208, db = 0.002385\n",
      "w1=7.224074, w2=9.473517, b=5.036446\n",
      "\n",
      "50th iteration:\n",
      "Loss = 0.000889, dw1 = -0.017366, dw2 = -0.024442, db = 0.002156\n",
      "w1=7.227940, w2=9.478958, b=5.035969\n",
      "\n",
      "51th iteration:\n",
      "Loss = 0.000718, dw1 = -0.015601, dw2 = -0.021958, db = 0.001947\n",
      "w1=7.231414, w2=9.483847, b=5.035538\n",
      "\n",
      "52th iteration:\n",
      "Loss = 0.000579, dw1 = -0.014015, dw2 = -0.019727, db = 0.001758\n",
      "w1=7.234534, w2=9.488238, b=5.035149\n",
      "\n",
      "53th iteration:\n",
      "Loss = 0.000468, dw1 = -0.012590, dw2 = -0.017722, db = 0.001586\n",
      "w1=7.237337, w2=9.492184, b=5.034797\n",
      "\n",
      "54th iteration:\n",
      "Loss = 0.000377, dw1 = -0.011311, dw2 = -0.015921, db = 0.001430\n",
      "w1=7.239855, w2=9.495728, b=5.034480\n",
      "\n",
      "55th iteration:\n",
      "Loss = 0.000305, dw1 = -0.010161, dw2 = -0.014303, db = 0.001289\n",
      "w1=7.242117, w2=9.498912, b=5.034194\n",
      "\n",
      "56th iteration:\n",
      "Loss = 0.000246, dw1 = -0.009128, dw2 = -0.012849, db = 0.001161\n",
      "w1=7.244149, w2=9.501773, b=5.033936\n",
      "\n",
      "57th iteration:\n",
      "Loss = 0.000198, dw1 = -0.008200, dw2 = -0.011543, db = 0.001046\n",
      "w1=7.245975, w2=9.504343, b=5.033704\n",
      "\n",
      "58th iteration:\n",
      "Loss = 0.000160, dw1 = -0.007367, dw2 = -0.010370, db = 0.000942\n",
      "w1=7.247615, w2=9.506651, b=5.033495\n",
      "\n",
      "59th iteration:\n",
      "Loss = 0.000129, dw1 = -0.006618, dw2 = -0.009317, db = 0.000848\n",
      "w1=7.249088, w2=9.508725, b=5.033306\n",
      "\n",
      "60th iteration:\n",
      "Loss = 0.000104, dw1 = -0.005946, dw2 = -0.008370, db = 0.000763\n",
      "w1=7.250412, w2=9.510589, b=5.033137\n",
      "\n",
      "61th iteration:\n",
      "Loss = 0.000084, dw1 = -0.005341, dw2 = -0.007519, db = 0.000687\n",
      "w1=7.251601, w2=9.512263, b=5.032984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x1 = np.linspace(-0.6,0.7,10)\n",
    "x2 = np.linspace(-0.9,0.92,10)\n",
    "\n",
    "y = 5 + 8*x1 + 9*x2\n",
    "\n",
    "# dw1\n",
    "# dw2, db\n",
    "\n",
    "eta = 0.2\n",
    "w1, w2, b = 0.3, 0.1, -0.3\n",
    "for i in range(100):\n",
    "    y_pred = b + (w1 * x1) + (w2 * x2)\n",
    "\n",
    "    L = np.mean((y - y_pred) ** 2) / 2\n",
    "\n",
    "    dw1 = -np.mean((y - y_pred) * x1)\n",
    "    dw2 = -np.mean((y - y_pred) * x2)\n",
    "    db = -np.mean(y - y_pred)\n",
    "\n",
    "    print(f\"{i+1}th iteration:\")\n",
    "    print(f\"Loss = {L:.6f}, dw1 = {dw1:.6f}, dw2 = {dw2:.6f}, db = {db:.6f}\")\n",
    "    print(f\"w1={w1:.6f}, w2={w2:.6f}, b={b:.6f}\\n\")\n",
    "    if L < 0.0001:\n",
    "        break\n",
    "    w1, w2, b = w1 - eta * dw1, w2 - eta * dw2, b - eta * db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46059cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w =  2.8344904011609597 b =  4.37409141363968\n",
      "Loss =  0.2439872496626577\n",
      "w =  2.999644499916011 b =  4.894869035610247\n",
      "Loss =  0.005538604792553377\n",
      "w =  3.003120495925965 b =  4.978489237403861\n",
      "Loss =  0.00021430224311760386\n",
      "w =  3.0010085087073324 b =  4.995150461760576\n",
      "Loss =  1.0674381186758593e-05\n",
      "Algo stopped at 4th iteration as Loss < Tolerance 0.0001\n"
     ]
    }
   ],
   "source": [
    "# for single variable only\n",
    "\n",
    "x = np.array([0.2, 1.2,1,1.4,-1.5,0.5,-0.5])\n",
    "y = 3 * x + 5\n",
    "eta = 0.2\n",
    "w,b = 0.3, 0.1\n",
    "tol = 0.0001\n",
    "\n",
    "tol = 0.0001\n",
    "n = len(x)\n",
    "\n",
    "for i in range(0,50):\n",
    "    for j in range(0,len(x)):\n",
    "        y_pred = w* x[j] + b\n",
    "        err = y[j] - y_pred\n",
    "        dw, db = -(err*x[j]),-err\n",
    "        new_w , new_b= w - eta*dw, b - eta*db\n",
    "        w,b = new_w, new_b\n",
    "    y_pred_all = w*x + b\n",
    "    err_all = y - y_pred_all\n",
    "    L = np.sum(err_all**2)/(2*n)\n",
    "    print(\"w = \", w, 'b = ', b)\n",
    "    print('Loss = ', L)\n",
    "    if L < tol:\n",
    "        print(f\"Algo stopped at {i+1}th iteration as Loss < Tolerance {tol}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2733e367",
   "metadata": {},
   "source": [
    "## Mini Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c19ae5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w =  3.0079424602735796 , b= 4.972191579612213\n",
      "Loss =  0.00034648090604227834\n",
      "w =  3.000284231813902 , b= 4.999566868938669\n",
      "Loss =  9.484121890159695e-08\n",
      "Algo stopped at 2th iteration as Loss < Tolerance 0.0001\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.2,1.2,1,1.4,-1.5,0.5,-0.5])\n",
    "y = 3*x + 5\n",
    "\n",
    "w = 0.3\n",
    "b = 0.1\n",
    "batches = [[0,6], [3,1,5],[4,2]]\n",
    "tol = 0.0001\n",
    "\n",
    "for i in range(0,50):\n",
    "    for j in range(0, len(x)):\n",
    "        for batch in batches:\n",
    "            y_pred = w*x[batch] +b\n",
    "            err = y[batch] - y_pred\n",
    "            dw, db = -np.sum(err*x[batch])/len(batch), -np.sum(err)/len(batch)\n",
    "            new_w, new_b = w - eta* dw, b - eta*db\n",
    "            w,b = new_w, new_b\n",
    "    y_pred_all = w*x + b\n",
    "    err_all = y-y_pred_all\n",
    "    L = np.sum(err_all**2)/(2*n)\n",
    "    print(\"w = \", w, \", b=\", b)\n",
    "    print(\"Loss = \", L)\n",
    "    if L < tol:\n",
    "        print(f'Algo stopped at {i+1}th iteration as Loss < Tolerance {tol}')\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d96fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
