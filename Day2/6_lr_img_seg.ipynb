{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80cc964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e960dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\\\meridianthe4\\\\PML\\\\Cases\\\\Image_Segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5132e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = pd.read_csv(\"Image_Segmentation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8514150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "region.centroid.col",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "region.centroid.row",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "region.pixel.count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "short.line.density.5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "short.line.density.2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vedge.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vegde.sd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge.sd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "intensity.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rawred.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rawblue.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rawgreen.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exred.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exblue.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exgreen.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "value.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "saturation.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hue-mean",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "261f01cc-f9c5-488a-96a8-235037ca6d3d",
       "rows": [
        [
         "0",
         "BRICKFACE",
         "188",
         "133",
         "9",
         "0.0",
         "0.0",
         "0.33333334",
         "0.26666674",
         "0.5",
         "0.077777736",
         "6.6666665",
         "8.333334",
         "7.7777777",
         "3.8888888",
         "5.0",
         "3.3333333",
         "-8.333333",
         "8.444445",
         "0.53858024",
         "-0.92481726"
        ],
        [
         "1",
         "BRICKFACE",
         "105",
         "139",
         "9",
         "0.0",
         "0.0",
         "0.27777782",
         "0.107407436",
         "0.83333325",
         "0.52222216",
         "6.111111",
         "7.5555553",
         "7.2222223",
         "3.5555556",
         "4.3333335",
         "3.3333333",
         "-7.6666665",
         "7.5555553",
         "0.5326279",
         "-0.96594584"
        ],
        [
         "2",
         "BRICKFACE",
         "34",
         "137",
         "9",
         "0.0",
         "0.0",
         "0.5000002",
         "0.16666673",
         "1.111111",
         "0.47407418",
         "5.851852",
         "7.7777777",
         "6.4444447",
         "3.3333333",
         "5.7777777",
         "1.7777778",
         "-7.5555553",
         "7.7777777",
         "0.57363313",
         "-0.74427164"
        ],
        [
         "3",
         "BRICKFACE",
         "39",
         "111",
         "9",
         "0.0",
         "0.0",
         "0.72222227",
         "0.37407416",
         "0.8888889",
         "0.4296295",
         "6.037037",
         "7.0",
         "7.6666665",
         "3.4444444",
         "2.8888888",
         "4.888889",
         "-7.7777777",
         "7.888889",
         "0.56291884",
         "-1.1757725"
        ],
        [
         "4",
         "BRICKFACE",
         "16",
         "128",
         "9",
         "0.0",
         "0.0",
         "0.5",
         "0.077777766",
         "0.66666675",
         "0.31111118",
         "5.5555553",
         "6.888889",
         "6.6666665",
         "3.1111112",
         "4.0",
         "3.3333333",
         "-7.3333335",
         "7.111111",
         "0.56150794",
         "-0.98581076"
        ],
        [
         "5",
         "BRICKFACE",
         "26",
         "67",
         "9",
         "0.11111111",
         "0.0",
         "1.0",
         "0.8888903",
         "2.4444447",
         "3.1851847",
         "20.0",
         "19.555555",
         "25.88889",
         "14.555555",
         "-1.3333334",
         "17.666666",
         "-16.333334",
         "25.88889",
         "0.4369392",
         "-1.6232022"
        ],
        [
         "6",
         "BRICKFACE",
         "14",
         "110",
         "9",
         "0.0",
         "0.0",
         "1.7222224",
         "5.3518505",
         "2.6666667",
         "1.0222229",
         "17.925926",
         "18.88889",
         "21.444445",
         "13.444445",
         "2.8888888",
         "10.555555",
         "-13.444445",
         "21.444445",
         "0.36884832",
         "-1.3450956"
        ],
        [
         "7",
         "BRICKFACE",
         "11",
         "108",
         "9",
         "0.0",
         "0.0",
         "1.3333335",
         "0.80000025",
         "1.3888888",
         "0.95185167",
         "17.666666",
         "19.0",
         "21.11111",
         "12.888889",
         "4.0",
         "10.333333",
         "-14.333333",
         "21.11111",
         "0.38875645",
         "-1.3021333"
        ],
        [
         "8",
         "BRICKFACE",
         "85",
         "101",
         "9",
         "0.0",
         "0.0",
         "1.3333334",
         "1.2888881",
         "1.2777777",
         "1.2185181",
         "21.296297",
         "21.222221",
         "26.777779",
         "15.888889",
         "-0.22222222",
         "16.444445",
         "-16.222221",
         "26.777779",
         "0.4047922",
         "-1.5585992"
        ],
        [
         "9",
         "BRICKFACE",
         "18",
         "145",
         "9",
         "0.0",
         "0.0",
         "0.38888896",
         "0.018518496",
         "0.6111111",
         "0.3740741",
         "3.925926",
         "5.5555553",
         "4.0",
         "2.2222223",
         "4.888889",
         "0.22222222",
         "-5.111111",
         "5.5555553",
         "0.6005291",
         "-0.57094"
        ],
        [
         "10",
         "BRICKFACE",
         "23",
         "55",
         "9",
         "0.0",
         "0.0",
         "2.2222216",
         "3.6740727",
         "1.7777773",
         "0.7851852",
         "23.444445",
         "21.666666",
         "31.11111",
         "17.555555",
         "-5.3333335",
         "23.0",
         "-17.666666",
         "31.11111",
         "0.43507022",
         "-1.7711632"
        ],
        [
         "11",
         "BRICKFACE",
         "196",
         "129",
         "9",
         "0.0",
         "0.0",
         "0.83333325",
         "0.43333334",
         "0.6666667",
         "0.17777774",
         "6.3333335",
         "7.888889",
         "7.3333335",
         "3.7777777",
         "4.6666665",
         "3.0",
         "-7.6666665",
         "8.222222",
         "0.54012346",
         "-0.9327826"
        ],
        [
         "12",
         "BRICKFACE",
         "80",
         "116",
         "9",
         "0.0",
         "0.0",
         "1.5",
         "1.6333328",
         "1.5555557",
         "0.87407404",
         "21.703703",
         "21.222221",
         "27.555555",
         "16.333334",
         "-1.4444444",
         "17.555555",
         "-16.11111",
         "27.555555",
         "0.40736422",
         "-1.6322426"
        ],
        [
         "13",
         "BRICKFACE",
         "2",
         "44",
         "9",
         "0.0",
         "0.0",
         "2.1666672",
         "2.3888876",
         "2.3888896",
         "1.5296285",
         "18.74074",
         "17.333334",
         "25.222221",
         "13.666667",
         "-4.2222223",
         "19.444445",
         "-15.222222",
         "25.222221",
         "0.45768142",
         "-1.7537255"
        ],
        [
         "14",
         "BRICKFACE",
         "120",
         "136",
         "9",
         "0.0",
         "0.0",
         "0.61111116",
         "0.4185187",
         "1.0000001",
         "0.4444444",
         "6.259259",
         "7.7777777",
         "7.2222223",
         "3.7777777",
         "4.5555553",
         "2.8888888",
         "-7.4444447",
         "8.0",
         "0.52954143",
         "-0.92460656"
        ],
        [
         "15",
         "BRICKFACE",
         "146",
         "124",
         "9",
         "0.0",
         "0.0",
         "0.4999999",
         "0.16666664",
         "0.38888875",
         "0.107407376",
         "6.037037",
         "7.4444447",
         "7.3333335",
         "3.3333333",
         "4.2222223",
         "3.8888888",
         "-8.111111",
         "7.6666665",
         "0.56349206",
         "-1.0247301"
        ],
        [
         "16",
         "BRICKFACE",
         "23",
         "85",
         "9",
         "0.0",
         "0.0",
         "1.4444445",
         "1.0518525",
         "1.777778",
         "0.96296287",
         "17.962963",
         "18.88889",
         "21.88889",
         "13.111111",
         "2.7777777",
         "11.777778",
         "-14.555555",
         "21.88889",
         "0.39975148",
         "-1.386867"
        ],
        [
         "17",
         "BRICKFACE",
         "138",
         "116",
         "9",
         "0.0",
         "0.0",
         "0.6111111",
         "0.15185188",
         "0.4444445",
         "0.20740739",
         "6.4814816",
         "7.5555553",
         "8.222222",
         "3.6666667",
         "3.2222223",
         "5.2222223",
         "-8.444445",
         "8.333334",
         "0.5591711",
         "-1.1910701"
        ],
        [
         "18",
         "BRICKFACE",
         "229",
         "124",
         "9",
         "0.0",
         "0.0",
         "0.888889",
         "0.074073985",
         "0.8888889",
         "0.3407407",
         "5.888889",
         "7.111111",
         "7.111111",
         "3.4444444",
         "3.6666667",
         "3.6666667",
         "-7.3333335",
         "7.5555553",
         "0.5458554",
         "-1.0376626"
        ],
        [
         "19",
         "BRICKFACE",
         "22",
         "116",
         "9",
         "0.0",
         "0.0",
         "0.38888875",
         "0.10740741",
         "0.33333325",
         "0.13333334",
         "5.6296296",
         "6.7777777",
         "7.0",
         "3.1111112",
         "3.4444444",
         "4.111111",
         "-7.5555553",
         "7.3333335",
         "0.57539684",
         "-1.0996237"
        ],
        [
         "20",
         "BRICKFACE",
         "121",
         "60",
         "9",
         "0.0",
         "0.0",
         "2.277778",
         "2.329629",
         "2.888889",
         "2.8740742",
         "26.74074",
         "24.666666",
         "35.22222",
         "20.333334",
         "-6.2222223",
         "25.444445",
         "-19.222221",
         "35.22222",
         "0.4223002",
         "-1.776113"
        ],
        [
         "21",
         "BRICKFACE",
         "33",
         "149",
         "9",
         "0.0",
         "0.0",
         "0.5555556",
         "0.25185165",
         "0.72222227",
         "0.15185171",
         "5.4444447",
         "4.111111",
         "8.666667",
         "3.5555556",
         "-4.0",
         "9.666667",
         "-5.6666665",
         "8.666667",
         "0.5783389",
         "-1.9857028"
        ],
        [
         "22",
         "BRICKFACE",
         "80",
         "95",
         "9",
         "0.0",
         "0.0",
         "1.2222223",
         "1.0074079",
         "0.944444",
         "0.5518514",
         "21.407408",
         "21.333334",
         "26.666666",
         "16.222223",
         "-0.22222222",
         "15.777778",
         "-15.555555",
         "26.666666",
         "0.39043593",
         "-1.5673273"
        ],
        [
         "23",
         "BRICKFACE",
         "96",
         "84",
         "9",
         "0.0",
         "0.0",
         "1.5000004",
         "1.2777773",
         "1.6111107",
         "2.2851882",
         "23.851852",
         "23.555555",
         "30.0",
         "18.0",
         "-0.8888889",
         "18.444445",
         "-17.555555",
         "30.0",
         "0.39879107",
         "-1.598867"
        ],
        [
         "24",
         "BRICKFACE",
         "145",
         "102",
         "9",
         "0.0",
         "0.0",
         "0.88888866",
         "0.6074083",
         "2.611111",
         "1.4851857",
         "23.074074",
         "22.11111",
         "29.777779",
         "17.333334",
         "-2.8888888",
         "20.11111",
         "-17.222221",
         "29.777779",
         "0.41776258",
         "-1.6854404"
        ],
        [
         "25",
         "BRICKFACE",
         "18",
         "138",
         "9",
         "0.0",
         "0.0",
         "0.88888884",
         "0.5629629",
         "0.83333325",
         "0.29999986",
         "5.740741",
         "7.3333335",
         "6.5555553",
         "3.3333333",
         "4.7777777",
         "2.4444444",
         "-7.2222223",
         "7.3333335",
         "0.5438712",
         "-0.8621077"
        ],
        [
         "26",
         "BRICKFACE",
         "138",
         "133",
         "9",
         "0.0",
         "0.0",
         "0.6666667",
         "0.44444433",
         "1.1666666",
         "0.21111093",
         "6.4444447",
         "7.7777777",
         "7.888889",
         "3.6666667",
         "4.0",
         "4.3333335",
         "-8.333333",
         "8.222222",
         "0.5582011",
         "-1.0776595"
        ],
        [
         "27",
         "BRICKFACE",
         "121",
         "113",
         "9",
         "0.0",
         "0.0",
         "1.722222",
         "1.5296303",
         "2.944444",
         "1.5296295",
         "20.25926",
         "20.0",
         "25.444445",
         "15.333333",
         "-0.7777778",
         "15.555555",
         "-14.777778",
         "25.444445",
         "0.39658895",
         "-1.5856091"
        ],
        [
         "28",
         "BRICKFACE",
         "95",
         "57",
         "9",
         "0.0",
         "0.0",
         "1.8333327",
         "3.4111106",
         "2.1111107",
         "1.7185175",
         "26.296297",
         "24.666666",
         "34.444447",
         "19.777779",
         "-4.888889",
         "24.444445",
         "-19.555555",
         "34.444447",
         "0.42569095",
         "-1.7390174"
        ],
        [
         "29",
         "SKY",
         "140",
         "25",
         "9",
         "0.0",
         "0.0",
         "0.99999875",
         "1.4666697",
         "1.1111107",
         "0.118517555",
         "128.0",
         "117.77778",
         "142.33334",
         "123.888885",
         "-30.666666",
         "43.0",
         "-12.333333",
         "142.33334",
         "0.17250364",
         "-2.3545518"
        ],
        [
         "30",
         "SKY",
         "142",
         "33",
         "9",
         "0.0",
         "0.0",
         "0.49999872",
         "0.62360865",
         "0.50000125",
         "0.3496027",
         "110.59259",
         "96.77778",
         "128.66667",
         "106.333336",
         "-41.444443",
         "54.22222",
         "-12.777778",
         "128.66667",
         "0.24777646",
         "-2.4080186"
        ],
        [
         "31",
         "SKY",
         "66",
         "41",
         "9",
         "0.0",
         "0.0",
         "0.61111194",
         "0.32773077",
         "0.38889185",
         "0.32773316",
         "109.703705",
         "95.111115",
         "128.88889",
         "105.111115",
         "-43.77778",
         "57.555557",
         "-13.777778",
         "128.88889",
         "0.26204562",
         "-2.404745"
        ],
        [
         "32",
         "SKY",
         "165",
         "99",
         "9",
         "0.0",
         "0.0",
         "0.88889056",
         "0.47407392",
         "0.7777786",
         "0.47407353",
         "93.40741",
         "79.0",
         "118.0",
         "83.22222",
         "-43.22222",
         "73.77778",
         "-30.555555",
         "118.0",
         "0.33041757",
         "-2.2077565"
        ],
        [
         "33",
         "SKY",
         "228",
         "20",
         "9",
         "0.0",
         "0.0",
         "1.0555547",
         "0.49065518",
         "0.8333333",
         "0.7527733",
         "125.0",
         "114.0",
         "140.55556",
         "120.44444",
         "-33.0",
         "46.666668",
         "-13.666667",
         "140.55556",
         "0.18889166",
         "-2.348006"
        ],
        [
         "34",
         "SKY",
         "124",
         "29",
         "9",
         "0.0",
         "0.0",
         "1.0000013",
         "0.7111076",
         "1.0555534",
         "0.90741664",
         "128.44444",
         "119.22222",
         "142.88889",
         "123.22222",
         "-27.666666",
         "43.333332",
         "-15.666667",
         "142.88889",
         "0.16561614",
         "-2.271128"
        ],
        [
         "35",
         "SKY",
         "156",
         "32",
         "9",
         "0.0",
         "0.0",
         "0.77777356",
         "0.16296418",
         "2.6111095",
         "1.0407379",
         "136.2963",
         "129.77779",
         "146.33334",
         "132.77779",
         "-19.555555",
         "30.11111",
         "-10.555555",
         "146.33334",
         "0.113055356",
         "-2.280755"
        ],
        [
         "36",
         "SKY",
         "21",
         "90",
         "9",
         "0.0",
         "0.0",
         "0.66666794",
         "0.044444147",
         "0.7777786",
         "0.56296283",
         "113.48148",
         "105.888885",
         "128.55556",
         "106.0",
         "-22.777779",
         "45.22222",
         "-22.444445",
         "128.55556",
         "0.17969723",
         "-2.0978148"
        ],
        [
         "37",
         "SKY",
         "8",
         "39",
         "9",
         "0.11111111",
         "0.0",
         "1.3888906",
         "1.129629",
         "1.8333334",
         "0.699999",
         "113.37037",
         "102.55556",
         "132.0",
         "105.55556",
         "-32.444443",
         "55.88889",
         "-23.444445",
         "132.0",
         "0.22295359",
         "-2.1981578"
        ],
        [
         "38",
         "SKY",
         "122",
         "11",
         "9",
         "0.0",
         "0.0",
         "1.0",
         "0.31111577",
         "2.8888905",
         "5.051852",
         "143.44444",
         "136.88889",
         "150.88889",
         "142.55556",
         "-19.666666",
         "22.333334",
         "-2.6666667",
         "150.88889",
         "0.09277301",
         "-2.5216477"
        ],
        [
         "39",
         "SKY",
         "44",
         "79",
         "9",
         "0.0",
         "0.0",
         "0.44444403",
         "0.34426486",
         "0.7777786",
         "0.4036864",
         "107.74074",
         "93.888885",
         "126.55556",
         "102.77778",
         "-41.555557",
         "56.444443",
         "-14.888889",
         "126.55556",
         "0.2580791",
         "-2.3779652"
        ],
        [
         "40",
         "SKY",
         "7",
         "18",
         "9",
         "0.0",
         "0.0",
         "1.2777786",
         "0.7296265",
         "0.9444453",
         "0.37407914",
         "138.62962",
         "133.33334",
         "147.55556",
         "135.0",
         "-15.888889",
         "26.777779",
         "-10.888889",
         "147.55556",
         "0.096352234",
         "-2.2146115"
        ],
        [
         "41",
         "SKY",
         "188",
         "42",
         "9",
         "0.0",
         "0.0",
         "0.7777786",
         "0.5443299",
         "1.6666679",
         "1.2649081",
         "108.92593",
         "95.666664",
         "126.22222",
         "104.888885",
         "-39.77778",
         "51.88889",
         "-12.111111",
         "126.22222",
         "0.24193405",
         "-2.4103878"
        ],
        [
         "42",
         "SKY",
         "152",
         "18",
         "9",
         "0.0",
         "0.0",
         "0.7777774",
         "0.4554219",
         "0.55555725",
         "0.2721644",
         "112.111115",
         "97.22222",
         "130.44444",
         "108.666664",
         "-44.666668",
         "55.0",
         "-10.333333",
         "130.44444",
         "0.2546684",
         "-2.45498"
        ],
        [
         "43",
         "SKY",
         "120",
         "74",
         "9",
         "0.0",
         "0.0",
         "0.3333346",
         "0.08888922",
         "0.50000125",
         "0.07777796",
         "101.85185",
         "89.111115",
         "123.22222",
         "93.22222",
         "-38.22222",
         "64.111115",
         "-25.88889",
         "123.22222",
         "0.2767844",
         "-2.2205532"
        ],
        [
         "44",
         "SKY",
         "143",
         "24",
         "9",
         "0.0",
         "0.0",
         "1.2777773",
         "0.9074056",
         "0.88888806",
         "1.1407489",
         "127.62963",
         "117.666664",
         "141.66667",
         "123.55556",
         "-29.88889",
         "42.11111",
         "-12.222222",
         "141.66667",
         "0.16939692",
         "-2.349252"
        ],
        [
         "45",
         "SKY",
         "181",
         "27",
         "9",
         "0.0",
         "0.0",
         "0.7222214",
         "0.46296388",
         "0.5",
         "0.25555483",
         "138.07408",
         "132.55556",
         "146.55556",
         "135.11111",
         "-16.555555",
         "25.444445",
         "-8.888889",
         "146.55556",
         "0.09626316",
         "-2.2645319"
        ],
        [
         "46",
         "SKY",
         "107",
         "21",
         "9",
         "0.0",
         "0.0",
         "0.66666156",
         "0.51639783",
         "1.1666666",
         "0.4082483",
         "126.77778",
         "115.77778",
         "141.88889",
         "122.666664",
         "-33.0",
         "45.333332",
         "-12.333333",
         "141.88889",
         "0.18402189",
         "-2.3703718"
        ],
        [
         "47",
         "SKY",
         "226",
         "83",
         "9",
         "0.0",
         "0.0",
         "0.8888893",
         "0.5185186",
         "1.0555521",
         "0.50740635",
         "90.62963",
         "74.55556",
         "116.888885",
         "80.44444",
         "-48.22222",
         "78.77778",
         "-30.555555",
         "116.888885",
         "0.36206177",
         "-2.2390528"
        ],
        [
         "48",
         "SKY",
         "93",
         "29",
         "9",
         "0.0",
         "0.0",
         "1.2222239",
         "1.2296363",
         "1.3888906",
         "1.5740819",
         "128.48148",
         "119.0",
         "142.77777",
         "123.666664",
         "-28.444445",
         "42.88889",
         "-14.444445",
         "142.77777",
         "0.16648434",
         "-2.2977605"
        ],
        [
         "49",
         "SKY",
         "60",
         "52",
         "9",
         "0.0",
         "0.0",
         "0.7222226",
         "0.5963011",
         "0.7777774",
         "0.7407436",
         "111.62963",
         "101.0",
         "129.22223",
         "104.666664",
         "-31.88889",
         "52.77778",
         "-20.88889",
         "129.22223",
         "0.21837935",
         "-2.2296848"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 209
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>region.centroid.col</th>\n",
       "      <th>region.centroid.row</th>\n",
       "      <th>region.pixel.count</th>\n",
       "      <th>short.line.density.5</th>\n",
       "      <th>short.line.density.2</th>\n",
       "      <th>vedge.mean</th>\n",
       "      <th>vegde.sd</th>\n",
       "      <th>hedge.mean</th>\n",
       "      <th>hedge.sd</th>\n",
       "      <th>intensity.mean</th>\n",
       "      <th>rawred.mean</th>\n",
       "      <th>rawblue.mean</th>\n",
       "      <th>rawgreen.mean</th>\n",
       "      <th>exred.mean</th>\n",
       "      <th>exblue.mean</th>\n",
       "      <th>exgreen.mean</th>\n",
       "      <th>value.mean</th>\n",
       "      <th>saturation.mean</th>\n",
       "      <th>hue-mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRICKFACE</td>\n",
       "      <td>188</td>\n",
       "      <td>133</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>8.333334</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>-8.333333</td>\n",
       "      <td>8.444445</td>\n",
       "      <td>0.538580</td>\n",
       "      <td>-0.924817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRICKFACE</td>\n",
       "      <td>105</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.107407</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>7.555555</td>\n",
       "      <td>7.222222</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>4.333334</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>-7.666666</td>\n",
       "      <td>7.555555</td>\n",
       "      <td>0.532628</td>\n",
       "      <td>-0.965946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRICKFACE</td>\n",
       "      <td>34</td>\n",
       "      <td>137</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.474074</td>\n",
       "      <td>5.851852</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>6.444445</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.777778</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>-7.555555</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>0.573633</td>\n",
       "      <td>-0.744272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRICKFACE</td>\n",
       "      <td>39</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.374074</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.429629</td>\n",
       "      <td>6.037037</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.666666</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>4.888889</td>\n",
       "      <td>-7.777778</td>\n",
       "      <td>7.888889</td>\n",
       "      <td>0.562919</td>\n",
       "      <td>-1.175773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRICKFACE</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>5.555555</td>\n",
       "      <td>6.888889</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>-7.333334</td>\n",
       "      <td>7.111111</td>\n",
       "      <td>0.561508</td>\n",
       "      <td>-0.985811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>GRASS</td>\n",
       "      <td>36</td>\n",
       "      <td>243</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>1.851851</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.711110</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>9.888889</td>\n",
       "      <td>12.111111</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-10.333333</td>\n",
       "      <td>-3.666667</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.452229</td>\n",
       "      <td>2.368311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>GRASS</td>\n",
       "      <td>186</td>\n",
       "      <td>218</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>13.703704</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>17.777779</td>\n",
       "      <td>-9.111111</td>\n",
       "      <td>-3.111111</td>\n",
       "      <td>12.222222</td>\n",
       "      <td>17.777779</td>\n",
       "      <td>0.401347</td>\n",
       "      <td>2.382684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>GRASS</td>\n",
       "      <td>197</td>\n",
       "      <td>236</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>6.829628</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>7.599998</td>\n",
       "      <td>16.074074</td>\n",
       "      <td>13.111111</td>\n",
       "      <td>16.666668</td>\n",
       "      <td>18.444445</td>\n",
       "      <td>-8.888889</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>7.111111</td>\n",
       "      <td>18.555555</td>\n",
       "      <td>0.292729</td>\n",
       "      <td>2.789800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>GRASS</td>\n",
       "      <td>208</td>\n",
       "      <td>240</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>0.862963</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>5.007407</td>\n",
       "      <td>14.148149</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.555555</td>\n",
       "      <td>-9.777778</td>\n",
       "      <td>-3.444444</td>\n",
       "      <td>13.222222</td>\n",
       "      <td>18.555555</td>\n",
       "      <td>0.421621</td>\n",
       "      <td>2.392487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>GRASS</td>\n",
       "      <td>223</td>\n",
       "      <td>185</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.349603</td>\n",
       "      <td>2.388889</td>\n",
       "      <td>2.080776</td>\n",
       "      <td>12.962963</td>\n",
       "      <td>11.555555</td>\n",
       "      <td>9.777778</td>\n",
       "      <td>17.555555</td>\n",
       "      <td>-4.222222</td>\n",
       "      <td>-9.555555</td>\n",
       "      <td>13.777778</td>\n",
       "      <td>17.555555</td>\n",
       "      <td>0.445418</td>\n",
       "      <td>1.838850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Class  region.centroid.col  region.centroid.row  region.pixel.count  \\\n",
       "0    BRICKFACE                  188                  133                   9   \n",
       "1    BRICKFACE                  105                  139                   9   \n",
       "2    BRICKFACE                   34                  137                   9   \n",
       "3    BRICKFACE                   39                  111                   9   \n",
       "4    BRICKFACE                   16                  128                   9   \n",
       "..         ...                  ...                  ...                 ...   \n",
       "204      GRASS                   36                  243                   9   \n",
       "205      GRASS                  186                  218                   9   \n",
       "206      GRASS                  197                  236                   9   \n",
       "207      GRASS                  208                  240                   9   \n",
       "208      GRASS                  223                  185                   9   \n",
       "\n",
       "     short.line.density.5  short.line.density.2  vedge.mean  vegde.sd  \\\n",
       "0                0.000000                   0.0    0.333333  0.266667   \n",
       "1                0.000000                   0.0    0.277778  0.107407   \n",
       "2                0.000000                   0.0    0.500000  0.166667   \n",
       "3                0.000000                   0.0    0.722222  0.374074   \n",
       "4                0.000000                   0.0    0.500000  0.077778   \n",
       "..                    ...                   ...         ...       ...   \n",
       "204              0.111111                   0.0    1.888889  1.851851   \n",
       "205              0.000000                   0.0    1.166667  0.744444   \n",
       "206              0.000000                   0.0    2.444444  6.829628   \n",
       "207              0.111111                   0.0    1.055556  0.862963   \n",
       "208              0.000000                   0.0    0.500000  0.349603   \n",
       "\n",
       "     hedge.mean  hedge.sd  intensity.mean  rawred.mean  rawblue.mean  \\\n",
       "0      0.500000  0.077778        6.666666     8.333334      7.777778   \n",
       "1      0.833333  0.522222        6.111111     7.555555      7.222222   \n",
       "2      1.111111  0.474074        5.851852     7.777778      6.444445   \n",
       "3      0.888889  0.429629        6.037037     7.000000      7.666666   \n",
       "4      0.666667  0.311111        5.555555     6.888889      6.666666   \n",
       "..          ...       ...             ...          ...           ...   \n",
       "204    2.000000  0.711110       13.333333     9.888889     12.111111   \n",
       "205    1.166667  0.655555       13.703704    10.666667     12.666667   \n",
       "206    3.333333  7.599998       16.074074    13.111111     16.666668   \n",
       "207    2.444444  5.007407       14.148149    10.888889     13.000000   \n",
       "208    2.388889  2.080776       12.962963    11.555555      9.777778   \n",
       "\n",
       "     rawgreen.mean  exred.mean  exblue.mean  exgreen.mean  value.mean  \\\n",
       "0         3.888889    5.000000     3.333333     -8.333333    8.444445   \n",
       "1         3.555556    4.333334     3.333333     -7.666666    7.555555   \n",
       "2         3.333333    5.777778     1.777778     -7.555555    7.777778   \n",
       "3         3.444444    2.888889     4.888889     -7.777778    7.888889   \n",
       "4         3.111111    4.000000     3.333333     -7.333334    7.111111   \n",
       "..             ...         ...          ...           ...         ...   \n",
       "204      18.000000  -10.333333    -3.666667     14.000000   18.000000   \n",
       "205      17.777779   -9.111111    -3.111111     12.222222   17.777779   \n",
       "206      18.444445   -8.888889     1.777778      7.111111   18.555555   \n",
       "207      18.555555   -9.777778    -3.444444     13.222222   18.555555   \n",
       "208      17.555555   -4.222222    -9.555555     13.777778   17.555555   \n",
       "\n",
       "     saturation.mean  hue-mean  \n",
       "0           0.538580 -0.924817  \n",
       "1           0.532628 -0.965946  \n",
       "2           0.573633 -0.744272  \n",
       "3           0.562919 -1.175773  \n",
       "4           0.561508 -0.985811  \n",
       "..               ...       ...  \n",
       "204         0.452229  2.368311  \n",
       "205         0.401347  2.382684  \n",
       "206         0.292729  2.789800  \n",
       "207         0.421621  2.392487  \n",
       "208         0.445418  1.838850  \n",
       "\n",
       "[209 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42fe54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = img_df.drop('Class', axis=1), img_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c750f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b8e82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82893e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "solver=['lbfgs','newton-cg','newton-cholesky','sag','saga']\n",
    "Cs=np.linspace(0.0001, 15, 20)\n",
    "penalties=['l2', None]\n",
    "scores=[]\n",
    "\n",
    "for s in solver:\n",
    "    for p in penalties:\n",
    "        for c in Cs:\n",
    "            try:\n",
    "                lr=LogisticRegression(penalty=p, solver=s, max_iter=1000, C=c)\n",
    "                lr.fit(X_train, y_train)\n",
    "                y_pred=lr.predict(X_test)\n",
    "                scores.append([s, p, c, accuracy_score(y_test, y_pred)])\n",
    "            except ValueError as e:\n",
    "                print(f\"Skipping solver={s}, penalty={p}, C={c:.4f}: {e}\")\n",
    "                scores.append([s, p, c, None])  # Include C value in error case\n",
    "            \n",
    "df_scores=pd.DataFrame(scores, columns=['solver', 'penalty', 'C', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17eed0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "solver",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "penalty",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "C",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "990449f8-6668-40d2-bcec-a07eaea50acb",
       "rows": [
        [
         "1",
         "lbfgs",
         "l2",
         "0.7895684210526316",
         "0.8809523809523809"
        ],
        [
         "2",
         "lbfgs",
         "l2",
         "1.5790368421052632",
         "0.8809523809523809"
        ],
        [
         "3",
         "lbfgs",
         "l2",
         "2.368505263157895",
         "0.8809523809523809"
        ],
        [
         "4",
         "lbfgs",
         "l2",
         "3.1579736842105266",
         "0.8809523809523809"
        ],
        [
         "6",
         "lbfgs",
         "l2",
         "4.736910526315789",
         "0.8809523809523809"
        ],
        [
         "5",
         "lbfgs",
         "l2",
         "3.9474421052631583",
         "0.8809523809523809"
        ],
        [
         "7",
         "lbfgs",
         "l2",
         "5.526378947368421",
         "0.8809523809523809"
        ],
        [
         "8",
         "lbfgs",
         "l2",
         "6.3158473684210525",
         "0.8809523809523809"
        ],
        [
         "68",
         "newton-cg",
         null,
         "6.3158473684210525",
         "0.8809523809523809"
        ],
        [
         "9",
         "lbfgs",
         "l2",
         "7.105315789473684",
         "0.8809523809523809"
        ],
        [
         "10",
         "lbfgs",
         "l2",
         "7.894784210526316",
         "0.8809523809523809"
        ],
        [
         "11",
         "lbfgs",
         "l2",
         "8.684252631578948",
         "0.8809523809523809"
        ],
        [
         "12",
         "lbfgs",
         "l2",
         "9.473721052631578",
         "0.8809523809523809"
        ],
        [
         "13",
         "lbfgs",
         "l2",
         "10.26318947368421",
         "0.8809523809523809"
        ],
        [
         "14",
         "lbfgs",
         "l2",
         "11.052657894736843",
         "0.8809523809523809"
        ],
        [
         "15",
         "lbfgs",
         "l2",
         "11.842126315789473",
         "0.8809523809523809"
        ],
        [
         "16",
         "lbfgs",
         "l2",
         "12.631594736842105",
         "0.8809523809523809"
        ],
        [
         "17",
         "lbfgs",
         "l2",
         "13.421063157894737",
         "0.8809523809523809"
        ],
        [
         "18",
         "lbfgs",
         "l2",
         "14.210531578947368",
         "0.8809523809523809"
        ],
        [
         "19",
         "lbfgs",
         "l2",
         "15.0",
         "0.8809523809523809"
        ],
        [
         "59",
         "newton-cg",
         "l2",
         "15.0",
         "0.8809523809523809"
        ],
        [
         "58",
         "newton-cg",
         "l2",
         "14.210531578947368",
         "0.8809523809523809"
        ],
        [
         "57",
         "newton-cg",
         "l2",
         "13.421063157894737",
         "0.8809523809523809"
        ],
        [
         "64",
         "newton-cg",
         null,
         "3.1579736842105266",
         "0.8809523809523809"
        ],
        [
         "56",
         "newton-cg",
         "l2",
         "12.631594736842105",
         "0.8809523809523809"
        ],
        [
         "55",
         "newton-cg",
         "l2",
         "11.842126315789473",
         "0.8809523809523809"
        ],
        [
         "53",
         "newton-cg",
         "l2",
         "10.26318947368421",
         "0.8809523809523809"
        ],
        [
         "54",
         "newton-cg",
         "l2",
         "11.052657894736843",
         "0.8809523809523809"
        ],
        [
         "51",
         "newton-cg",
         "l2",
         "8.684252631578948",
         "0.8809523809523809"
        ],
        [
         "50",
         "newton-cg",
         "l2",
         "7.894784210526316",
         "0.8809523809523809"
        ],
        [
         "49",
         "newton-cg",
         "l2",
         "7.105315789473684",
         "0.8809523809523809"
        ],
        [
         "52",
         "newton-cg",
         "l2",
         "9.473721052631578",
         "0.8809523809523809"
        ],
        [
         "48",
         "newton-cg",
         "l2",
         "6.3158473684210525",
         "0.8809523809523809"
        ],
        [
         "47",
         "newton-cg",
         "l2",
         "5.526378947368421",
         "0.8809523809523809"
        ],
        [
         "45",
         "newton-cg",
         "l2",
         "3.9474421052631583",
         "0.8809523809523809"
        ],
        [
         "46",
         "newton-cg",
         "l2",
         "4.736910526315789",
         "0.8809523809523809"
        ],
        [
         "44",
         "newton-cg",
         "l2",
         "3.1579736842105266",
         "0.8809523809523809"
        ],
        [
         "43",
         "newton-cg",
         "l2",
         "2.368505263157895",
         "0.8809523809523809"
        ],
        [
         "42",
         "newton-cg",
         "l2",
         "1.5790368421052632",
         "0.8809523809523809"
        ],
        [
         "41",
         "newton-cg",
         "l2",
         "0.7895684210526316",
         "0.8809523809523809"
        ],
        [
         "70",
         "newton-cg",
         null,
         "7.894784210526316",
         "0.8809523809523809"
        ],
        [
         "65",
         "newton-cg",
         null,
         "3.9474421052631583",
         "0.8809523809523809"
        ],
        [
         "66",
         "newton-cg",
         null,
         "4.736910526315789",
         "0.8809523809523809"
        ],
        [
         "67",
         "newton-cg",
         null,
         "5.526378947368421",
         "0.8809523809523809"
        ],
        [
         "60",
         "newton-cg",
         null,
         "0.0001",
         "0.8809523809523809"
        ],
        [
         "61",
         "newton-cg",
         null,
         "0.7895684210526316",
         "0.8809523809523809"
        ],
        [
         "62",
         "newton-cg",
         null,
         "1.5790368421052632",
         "0.8809523809523809"
        ],
        [
         "63",
         "newton-cg",
         null,
         "2.368505263157895",
         "0.8809523809523809"
        ],
        [
         "71",
         "newton-cg",
         null,
         "8.684252631578948",
         "0.8809523809523809"
        ],
        [
         "69",
         "newton-cg",
         null,
         "7.105315789473684",
         "0.8809523809523809"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 200
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solver</th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.789568</td>\n",
       "      <td>0.880952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.579037</td>\n",
       "      <td>0.880952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>2.368505</td>\n",
       "      <td>0.880952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>3.157974</td>\n",
       "      <td>0.880952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>4.736911</td>\n",
       "      <td>0.880952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>saga</td>\n",
       "      <td>None</td>\n",
       "      <td>11.842126</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>saga</td>\n",
       "      <td>None</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>saga</td>\n",
       "      <td>None</td>\n",
       "      <td>13.421063</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    solver penalty          C     score\n",
       "1    lbfgs      l2   0.789568  0.880952\n",
       "2    lbfgs      l2   1.579037  0.880952\n",
       "3    lbfgs      l2   2.368505  0.880952\n",
       "4    lbfgs      l2   3.157974  0.880952\n",
       "6    lbfgs      l2   4.736911  0.880952\n",
       "..     ...     ...        ...       ...\n",
       "195   saga    None  11.842126  0.809524\n",
       "199   saga    None  15.000000  0.809524\n",
       "197   saga    None  13.421063  0.809524\n",
       "120    sag      l2   0.000100  0.642857\n",
       "160   saga      l2   0.000100  0.642857\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41f6ab7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination:\n",
      "Solver: lbfgs\n",
      "Penalty: l2\n",
      "C: 0.7896\n",
      "Accuracy: 0.8810\n"
     ]
    }
   ],
   "source": [
    "# Find the best parameters\n",
    "best_row = df_scores.loc[df_scores['score'].idxmax()]\n",
    "print(f\"\\nBest combination:\")\n",
    "print(f\"Solver: {best_row['solver']}\")\n",
    "print(f\"Penalty: {best_row['penalty']}\")\n",
    "print(f\"C: {best_row['C']:.4f}\")\n",
    "print(f\"Accuracy: {best_row['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d82396f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\meridianthe4\\PML\\main\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.7896, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">0.7896</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.7896, max_iter=1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = LogisticRegression(penalty='l2', solver='lbfgs', C=0.7896, max_iter=1000)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f3a4339",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df = pd.read_csv('tst_img.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cc09cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = best_model.predict(tst_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5017b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df['predicted category'] = pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62d81697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "region.centroid.col",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "region.centroid.row",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "region.pixel.count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "short.line.density.5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "short.line.density.2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "vedge.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vegde.sd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge.sd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "intensity.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rawred.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rawblue.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rawgreen.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exred.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exblue.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exgreen.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "value.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "saturation.mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hue-mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "predicted category",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "39b59e20-7904-481b-8eb8-cf216fbcf451",
       "rows": [
        [
         "0",
         "22",
         "90",
         "10",
         "0",
         "0",
         "0.66666794",
         "0.044444147",
         "0.88",
         "0.56296283",
         "112.0",
         "105.888885",
         "128.55556",
         "106.0",
         "-22.777779",
         "45.22222",
         "-22.444445",
         "128.55556",
         "0.17969723",
         "-2.0978148",
         "SKY"
        ],
        [
         "1",
         "210",
         "200",
         "9",
         "0",
         "0",
         "1.3",
         "0.9981452",
         "1.6111107",
         "1.1238158",
         "49.48148",
         "45.0",
         "60.666668",
         "43.0",
         "-14.111111",
         "35.0",
         "-19.444445",
         "60.666668",
         "0.29078844",
         "-1.9875989",
         "PATH"
        ],
        [
         "2",
         "240",
         "184",
         "9",
         "0",
         "0",
         "0.5000002",
         "0.077777766",
         "0.7777777",
         "0.785185",
         "11.851851",
         "9.777778",
         "9.888889",
         "15.888889",
         "-5.0",
         "-5.888889",
         "13.0",
         "15.888889",
         "0.5",
         "2.1286457",
         "GRASS"
        ],
        [
         "3",
         "130",
         "191",
         "9",
         "0",
         "0",
         "1.0",
         "0.4",
         "1.5",
         "1.0111109",
         "7.3333335",
         "5.3333335",
         "5.0",
         "11.222222",
         "-7.0",
         "-5.6666665",
         "11.666667",
         "11.222222",
         "0.5358197",
         "2.1224225",
         "GRASS"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region.centroid.col</th>\n",
       "      <th>region.centroid.row</th>\n",
       "      <th>region.pixel.count</th>\n",
       "      <th>short.line.density.5</th>\n",
       "      <th>short.line.density.2</th>\n",
       "      <th>vedge.mean</th>\n",
       "      <th>vegde.sd</th>\n",
       "      <th>hedge.mean</th>\n",
       "      <th>hedge.sd</th>\n",
       "      <th>intensity.mean</th>\n",
       "      <th>rawred.mean</th>\n",
       "      <th>rawblue.mean</th>\n",
       "      <th>rawgreen.mean</th>\n",
       "      <th>exred.mean</th>\n",
       "      <th>exblue.mean</th>\n",
       "      <th>exgreen.mean</th>\n",
       "      <th>value.mean</th>\n",
       "      <th>saturation.mean</th>\n",
       "      <th>hue-mean</th>\n",
       "      <th>predicted category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666668</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.562963</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>105.888885</td>\n",
       "      <td>128.555560</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>-22.777779</td>\n",
       "      <td>45.222220</td>\n",
       "      <td>-22.444445</td>\n",
       "      <td>128.555560</td>\n",
       "      <td>0.179697</td>\n",
       "      <td>-2.097815</td>\n",
       "      <td>SKY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210</td>\n",
       "      <td>200</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.998145</td>\n",
       "      <td>1.611111</td>\n",
       "      <td>1.123816</td>\n",
       "      <td>49.481480</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>60.666668</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>-14.111111</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>-19.444445</td>\n",
       "      <td>60.666668</td>\n",
       "      <td>0.290788</td>\n",
       "      <td>-1.987599</td>\n",
       "      <td>PATH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240</td>\n",
       "      <td>184</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>11.851851</td>\n",
       "      <td>9.777778</td>\n",
       "      <td>9.888889</td>\n",
       "      <td>15.888889</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-5.888889</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.888889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.128646</td>\n",
       "      <td>GRASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130</td>\n",
       "      <td>191</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.011111</td>\n",
       "      <td>7.333334</td>\n",
       "      <td>5.333334</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.222222</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-5.666666</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>11.222222</td>\n",
       "      <td>0.535820</td>\n",
       "      <td>2.122422</td>\n",
       "      <td>GRASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region.centroid.col  region.centroid.row  region.pixel.count  \\\n",
       "0                   22                   90                  10   \n",
       "1                  210                  200                   9   \n",
       "2                  240                  184                   9   \n",
       "3                  130                  191                   9   \n",
       "\n",
       "   short.line.density.5  short.line.density.2  vedge.mean  vegde.sd  \\\n",
       "0                     0                     0    0.666668  0.044444   \n",
       "1                     0                     0    1.300000  0.998145   \n",
       "2                     0                     0    0.500000  0.077778   \n",
       "3                     0                     0    1.000000  0.400000   \n",
       "\n",
       "   hedge.mean  hedge.sd  intensity.mean  rawred.mean  rawblue.mean  \\\n",
       "0    0.880000  0.562963      112.000000   105.888885    128.555560   \n",
       "1    1.611111  1.123816       49.481480    45.000000     60.666668   \n",
       "2    0.777778  0.785185       11.851851     9.777778      9.888889   \n",
       "3    1.500000  1.011111        7.333334     5.333334      5.000000   \n",
       "\n",
       "   rawgreen.mean  exred.mean  exblue.mean  exgreen.mean  value.mean  \\\n",
       "0     106.000000  -22.777779    45.222220    -22.444445  128.555560   \n",
       "1      43.000000  -14.111111    35.000000    -19.444445   60.666668   \n",
       "2      15.888889   -5.000000    -5.888889     13.000000   15.888889   \n",
       "3      11.222222   -7.000000    -5.666666     11.666667   11.222222   \n",
       "\n",
       "   saturation.mean  hue-mean predicted category  \n",
       "0         0.179697 -2.097815                SKY  \n",
       "1         0.290788 -1.987599               PATH  \n",
       "2         0.500000  2.128646              GRASS  \n",
       "3         0.535820  2.122422              GRASS  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
